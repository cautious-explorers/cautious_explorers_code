{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd95fab-cfd0-447b-8db2-397c3b1c7400",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "In this notebook, we show the processing steps of the data.  \n",
    "The raw data can be requested at https://journals.aps.org/datasets, where the introduction of data can also be acquired.  \n",
    "In the **structralize source data** section, we handle the raw json files into a structured data table of paper information.  \n",
    "In the **count 5-year citations** section, we count the citations each paper received in five years after its publication, then we take the log-citations as our evaluation metrics of scholar impact.  \n",
    "In the **assgin areas and topics** section, we assgin the PACS code to each paper.  \n",
    "In the **name disambiguation** section, we do name disambiguation for authors using their public information. Thus we can have an accurate publication list for each author.  \n",
    "In the **EP&ED** section, we show our calculation process of exploratory propensity(EP) and exploratory distance(ED) based on PACS codes.  \n",
    "In the **select scientists** section, we select authors who have at least 10 publications as our study objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b2d118a-8f91-4164-b0af-990d4bc190a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5_1_PSW.R', '6_temporal_perspectives.ipynb', 'draw', '3_sample_scientist.ipynb', '2_interplays.ipynb', '4_regression_result.ipynb', '.ipynb_checkpoints', '5_2_PSW_result.ipynb', '1_processed_data.ipynb', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "import matplotlib\n",
    "import statistics \n",
    "import math\n",
    "import pickle\n",
    "import scipy.io as scio\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "def save_pkl(path,obj):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj,f)\n",
    "        \n",
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b95e12-2f5e-451e-9a0a-13e83d442988",
   "metadata": {},
   "source": [
    "## structuralize source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb0a430-9f54-49fa-8970-994baf00d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1031it [19:28,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "paper_doi = []\n",
    "authors_name = []\n",
    "dates = []\n",
    "paper_type =[]\n",
    "for pairs in tqdm.tqdm(os.walk(\"../raw_data/aps-dataset-metadata-2020/\", topdown=False)):# the path where you put the source file from APS\n",
    "    root = pairs[0]\n",
    "    files = pairs[2]\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        author_name = []\n",
    "        with open(path, 'r') as f:   #read json files\n",
    "            data = json.load(f)  \n",
    "            \n",
    "            date_list = list(map(int,data['date'].split('-')))\n",
    "            date = datetime.date(date_list[0],date_list[1],date_list[2])\n",
    "            dates.append(date)\n",
    "            \n",
    "            paper_doi.append(data['id'])\n",
    "            \n",
    "            if 'articleType' in data.keys():\n",
    "                paper_type.append(data['articleType'])\n",
    "            else:\n",
    "                paper_type.append(None)\n",
    "                \n",
    "            if 'authors' in data.keys():\n",
    "                for i in range(len(data['authors'])):\n",
    "                    author_name.append(data['authors'][i]['name'])\n",
    "            else:\n",
    "                author_name = None\n",
    "            authors_name.append(author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07bbab9-e014-48b0-80c4-77798787a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_paper_data = pd.DataFrame({\n",
    "    'paperDoi':paper_doi,\n",
    "    'authorName':authors_name,\n",
    "    'date':dates,\n",
    "    'type':paper_type\n",
    "})\n",
    "# save_pkl('../data/processing_data/meta_paper_data.pkl', meta_paper_data) # if you want to save the file, uncomment the line:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b4aaf5-f8c9-48c0-a6c5-3908b49a9b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1893, 7, 1), datetime.date(2020, 12, 31), 678961)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_paper_data.date.min(),meta_paper_data.date.max(),len(meta_paper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef67f99-4617-4bf1-97a6-bec86673bcdd",
   "metadata": {},
   "source": [
    "## count five-year citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de07071c-9a4b-4bdc-b82c-4e47f12dbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_paper_data = load_pkl('./meta_paper_data.pkl') # if you want to read the file, uncomment the line:)\n",
    "doi_date = dict(zip(meta_paper_data.paperDoi,meta_paper_data.date))\n",
    "cit_pair = pd.read_csv('../raw_data/aps-dataset-citations-2020.csv') # the path where you put the source file from APS\n",
    "cit_pair_with_time = pd.merge(cit_pair, meta_paper_data[['paperDoi','date']].rename(columns={'paperDoi':'citing_doi','date':'citing_pubdate'}), on='citing_doi', how='left').drop_duplicates()\n",
    "cit_pair_with_time = pd.merge(cit_pair_with_time, meta_paper_data[['paperDoi','date']].rename(columns={'paperDoi':'cited_doi','date':'cited_pubdate'}), on='cited_doi', how='left').drop_duplicates()\n",
    "cit_pair_with_time = cit_pair_with_time.dropna().reset_index(drop=True)# delete record without time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f67d38f-fe29-4c1f-918a-096cbbbc88eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8767868/8767868 [05:15<00:00, 27815.33it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 5 # time windows for citation count\n",
    "citation_dict = {}\n",
    "reference_dict = {}\n",
    "\n",
    "for i in tqdm.tqdm(range(len(cit_pair_with_time))):\n",
    "    cited_pub_i = cit_pair_with_time.cited_pubdate.iloc[i]\n",
    "    citing_pub_i = cit_pair_with_time.citing_pubdate.iloc[i]\n",
    "    delta = citing_pub_i-cited_pub_i\n",
    "    cited_doi_i = cit_pair_with_time.cited_doi.iloc[i]\n",
    "    citing_doi_i = cit_pair_with_time.citing_doi.iloc[i]\n",
    "    \n",
    "    #for cited list\n",
    "    if (delta>=datetime.timedelta(days=0))&(delta<=datetime.timedelta(days=n*365)): ##5years= 365*5 days\n",
    "        if cited_doi_i in citation_dict.keys():\n",
    "            citation_dict[cited_doi_i].add(citing_doi_i)\n",
    "        else:\n",
    "            citation_dict[cited_doi_i] = set([citing_doi_i])\n",
    "\n",
    "    #for reference list\n",
    "    if citing_doi_i in reference_dict.keys():\n",
    "        reference_dict[citing_doi_i].add(cited_doi_i)\n",
    "    else:\n",
    "        reference_dict[citing_doi_i] = set([cited_doi_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be849cb6-4543-4a77-add8-6f5b395fa015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678916/678916 [00:06<00:00, 98541.31it/s] \n"
     ]
    }
   ],
   "source": [
    "meta_paper_data = meta_paper_data.drop_duplicates(subset=['paperDoi', 'date'])\n",
    "citations = []\n",
    "references = []\n",
    "cit_count =[]\n",
    "ref_count = []\n",
    "for i in tqdm.tqdm(range(len(meta_paper_data))):\n",
    "    paperdoi = meta_paper_data.paperDoi.iloc[i]\n",
    "    if paperdoi in citation_dict.keys():\n",
    "        citations.append(citation_dict[paperdoi])\n",
    "        cit_count.append(len(citation_dict[paperdoi]))\n",
    "    else:\n",
    "        citations.append(set([]))\n",
    "        cit_count.append(0)\n",
    "    if paperdoi in reference_dict.keys():\n",
    "        references.append(reference_dict[paperdoi])\n",
    "        ref_count.append(len(reference_dict[paperdoi]))\n",
    "    else:\n",
    "        references.append(set([]))\n",
    "        ref_count.append(0)\n",
    "\n",
    "meta_paper_data_2 = meta_paper_data.copy()\n",
    "meta_paper_data_2['citations'] = citations\n",
    "meta_paper_data_2['citCount'] = cit_count\n",
    "meta_paper_data_2['references'] = references\n",
    "meta_paper_data_2['refCount'] = ref_count\n",
    "\n",
    "meta_paper_data_2 = meta_paper_data_2.drop_duplicates(subset=['paperDoi', 'date']).reset_index(drop = True)\n",
    "save_pkl('../data/processing_data/meta_paper_data_2.pkl',meta_paper_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f536d7d-bef7-47d5-ba26-254017f86b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc5e036b310>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_paper_data_2['logCit'] = [np.log(i+1) for i in meta_paper_data_2['citCount']]\n",
    "meta_paper_data_2['year'] = [i.year for i in meta_paper_data_2['date']]\n",
    "plt.plot(meta_paper_data_2.groupby('year').logCit.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fb0b7-8700-48af-98e8-96b9bbf42537",
   "metadata": {},
   "source": [
    "## assgin areas and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebc1cc4-644d-4d8f-8b04-5ef71ad86318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441340/441340 [00:03<00:00, 118487.09it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 122874.40it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 128837.60it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 134619.79it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 140528.30it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 125935.97it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 126051.44it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 128907.28it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 134885.05it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 138198.59it/s]\n",
      "100%|██████████| 441340/441340 [00:00<00:00, 914387.82it/s]\n"
     ]
    }
   ],
   "source": [
    "PACS = pd.read_csv('/public/aps/raw_data/PACS.txt', keep_default_na=False)\n",
    "def get_genre(name):\n",
    "    PACS_code = []\n",
    "    for i in tqdm.tqdm(range(len(PACS))):\n",
    "        p_code = re.match(r'((.*)([0-9]{4})(.*))', str(PACS[name].iloc[i]).replace('.','').replace(' ','').replace(':',''))\n",
    "        if p_code:\n",
    "            if p_code.group(1)[:2].isdigit():\n",
    "                PACS_code.append(p_code.group(1)[:6].replace('−','-').replace('–','-'))\n",
    "            else:\n",
    "                PACS_code.append(None)\n",
    "        else:\n",
    "            PACS_code.append(None)\n",
    "    return PACS_code\n",
    "\n",
    "genres_set = set(get_genre('PACS1') + get_genre('PACS2') + get_genre('PACS3') + get_genre('PACS4') + get_genre('PACS5'))\n",
    "\n",
    "PACS1 = get_genre('PACS1')\n",
    "PACS2 = get_genre('PACS2')\n",
    "PACS3 = get_genre('PACS3')\n",
    "PACS4 = get_genre('PACS4')\n",
    "PACS5 = get_genre('PACS5')\n",
    "\n",
    "genres_list = []\n",
    "for i in tqdm.tqdm(range(len(PACS))):\n",
    "    gl = [PACS1[i],PACS2[i],PACS3[i],PACS4[i],PACS5[i]]\n",
    "    while None in gl:\n",
    "        gl.remove(None)\n",
    "    genres_list.append(gl)\n",
    "    \n",
    "doi_cor_genre = dict(zip(PACS.DOI,genres_list))\n",
    "len(doi_cor_genre)\n",
    "doi_cor_genre['10.1103/PhysRevA.60.R2614'] = ['0365Bz', '4250Dv', '89701c']\n",
    "doi_cor_genre['10.1103/PhysRevB.66.104415'] = ['7570Pa', '71301h', '78202e']\n",
    "doi_cor_genre['10.1103/PhysRevE.65.026128'] = ['05202y', '04402b', '05901m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c49e2a8-1112-4038-ad97-94407f9c7481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678916/678916 [00:09<00:00, 71402.03it/s] \n"
     ]
    }
   ],
   "source": [
    "genres = []\n",
    "for i in tqdm.tqdm(range(len(meta_paper_data_2))):\n",
    "    if meta_paper_data_2.paperDoi.iloc[i] in doi_cor_genre.keys():\n",
    "        genres.append(doi_cor_genre[meta_paper_data_2.paperDoi.iloc[i]])\n",
    "    else:\n",
    "        genres.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210a5a62-d19d-48ed-b6fc-35e19c7d19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_paper_data_3 = meta_paper_data_2.copy()\n",
    "meta_paper_data_3['genres'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5161c06d-f4ab-405c-8b68-1f8b845f3c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paperDoi     0.00\n",
       "authorName   0.00\n",
       "date         0.00\n",
       "type         0.00\n",
       "citations    0.00\n",
       "citCount     0.00\n",
       "references   0.00\n",
       "refCount     0.00\n",
       "logCit       0.00\n",
       "year         0.00\n",
       "genres       0.10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_paper_data_3 = meta_paper_data_3.dropna(subset=['authorName','date','paperDoi']).reset_index(drop=True)\n",
    "part = meta_paper_data_3[(meta_paper_data_3.date>=datetime.date(1976,1,1))&(meta_paper_data_3.date<=datetime.date(2015,12,31))]\n",
    "part.isnull().sum()/len(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e848bb89-afe0-404a-9c96-6a04840ef2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../data/processing_data/meta_paper_data_3.pkl',meta_paper_data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcb5f3-a83d-4c6e-a527-91f0d2e85dfd",
   "metadata": {},
   "source": [
    "## name disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034e20b-2acb-4116-9f0d-7193d8ae8300",
   "metadata": {},
   "source": [
    "### build data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc613597-49c9-41bb-9275-05c315ed0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1031it [11:17,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_doi = []\n",
    "authors_name = []\n",
    "dates = []\n",
    "paper_affs = []\n",
    "for pairs in tqdm.tqdm(os.walk(\"/public/aps/raw_data/aps-dataset-metadata-2020/\", topdown=False)):\n",
    "    root = pairs[0]\n",
    "    files = pairs[2]\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        author_name = []\n",
    "        with open(path, 'r') as f:   #read json files\n",
    "            data = json.load(f)  \n",
    "            \n",
    "            date_list = list(map(int,data['date'].split('-'))) ##split features and store them in list\n",
    "            date = datetime.date(date_list[0],date_list[1],date_list[2])\n",
    "            dates.append(date)\n",
    "            \n",
    "            paper_doi.append(data['id'])\n",
    "                \n",
    "            if 'authors' in data.keys():\n",
    "                for i in range(len(data['authors'])):\n",
    "                    if 'affiliationIds' in data['authors'][i].keys():\n",
    "                        author_name.append((data['authors'][i]['name'], data['authors'][i]['affiliationIds']))\n",
    "                    else:\n",
    "                        author_name.append((data['authors'][i]['name'], 'no aff id'))\n",
    "\n",
    "            else: ##some authors do not have name\n",
    "                author_name = None\n",
    "            authors_name.append(author_name)\n",
    "            \n",
    "            if 'affiliations' in data.keys():\n",
    "                aff_dict = {}\n",
    "                for aff in data['affiliations']:\n",
    "                    aff_dict[aff['id']]=aff['name']\n",
    "                paper_affs.append(aff_dict)\n",
    "            else:\n",
    "                paper_affs.append('no aff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3b887bb-1e28-43f9-adef-60d57abfeb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.DataFrame({\n",
    "    'paperDoi':paper_doi,\n",
    "    'authorName':authors_name,\n",
    "    'date':dates,\n",
    "    'paperAff':paper_affs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110ee7-b677-45f3-af3f-0e4cd80f62c1",
   "metadata": {},
   "source": [
    "### processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11a2d897-f420-455a-9b99-262b893e76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "512d66db-aea4-4e0e-a8fe-24890f50d8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperDoi</th>\n",
       "      <th>authorName</th>\n",
       "      <th>date</th>\n",
       "      <th>paperAff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1103/PhysRevAccelBeams.20.091002</td>\n",
       "      <td>[(E. Quaranta, [a1]), (A. Bertarelli, [a1]), (...</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>{'a1': 'CERN, CH-1211 Geneva 23, Switzerland',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1103/PhysRevAccelBeams.20.023401</td>\n",
       "      <td>[(Han-Jie Cai, [a1, a2]), (Guanghui Yang, [a1,...</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>{'a1': 'Institute of Modern Physics, CAS, Lanz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1103/PhysRevAccelBeams.20.042002</td>\n",
       "      <td>[(Thomas Flisgen, [a1]), (Johann Heller, [a1])...</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>{'a1': 'Universität Rostock, Institut für Allg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1103/PhysRevAccelBeams.20.040402</td>\n",
       "      <td>[(W. A. Stygar, [a1]), (K. R. LeChien, [a2]), ...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>{'a1': 'Sandia National Laboratories, Albuquer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1103/PhysRevAccelBeams.20.064801</td>\n",
       "      <td>[(Jui-Che Huang, [a1]), (Hideo Kitamura, [a2])...</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>{'a1': 'National Synchrotron Radiation Researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669337</th>\n",
       "      <td>10.1103/PhysRevSeriesI.27.1</td>\n",
       "      <td>[(Herbert G. Dorsey, [a1])]</td>\n",
       "      <td>1908-07-01</td>\n",
       "      <td>{'a1': 'Physical Laboratory, Cornell University'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669338</th>\n",
       "      <td>10.1103/PhysRevSeriesI.27.27</td>\n",
       "      <td>[(S. R. Williams., [a1])]</td>\n",
       "      <td>1908-07-01</td>\n",
       "      <td>{'a1': 'Barnard College, Columbia University, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669339</th>\n",
       "      <td>10.1103/PhysRevSeriesI.27.141</td>\n",
       "      <td>[(Anthony Zeleny, [a1])]</td>\n",
       "      <td>1908-08-01</td>\n",
       "      <td>{'a1': 'Physical Laboratory, University of Min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669340</th>\n",
       "      <td>10.1103/PhysRevSeriesI.27.76</td>\n",
       "      <td>[(Frances G. Wick, [a1])]</td>\n",
       "      <td>1908-08-01</td>\n",
       "      <td>{'a1': 'Physical Laboratory, Cornell Universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669341</th>\n",
       "      <td>10.1103/PhysRevSeriesI.27.515</td>\n",
       "      <td>[]</td>\n",
       "      <td>1908-12-01</td>\n",
       "      <td>no aff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669342 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paperDoi  \\\n",
       "0       10.1103/PhysRevAccelBeams.20.091002   \n",
       "1       10.1103/PhysRevAccelBeams.20.023401   \n",
       "2       10.1103/PhysRevAccelBeams.20.042002   \n",
       "3       10.1103/PhysRevAccelBeams.20.040402   \n",
       "4       10.1103/PhysRevAccelBeams.20.064801   \n",
       "...                                     ...   \n",
       "669337          10.1103/PhysRevSeriesI.27.1   \n",
       "669338         10.1103/PhysRevSeriesI.27.27   \n",
       "669339        10.1103/PhysRevSeriesI.27.141   \n",
       "669340         10.1103/PhysRevSeriesI.27.76   \n",
       "669341        10.1103/PhysRevSeriesI.27.515   \n",
       "\n",
       "                                               authorName        date  \\\n",
       "0       [(E. Quaranta, [a1]), (A. Bertarelli, [a1]), (...  2017-09-13   \n",
       "1       [(Han-Jie Cai, [a1, a2]), (Guanghui Yang, [a1,...  2017-02-01   \n",
       "2       [(Thomas Flisgen, [a1]), (Johann Heller, [a1])...  2017-04-18   \n",
       "3       [(W. A. Stygar, [a1]), (K. R. LeChien, [a2]), ...  2017-04-07   \n",
       "4       [(Jui-Che Huang, [a1]), (Hideo Kitamura, [a2])...  2017-06-29   \n",
       "...                                                   ...         ...   \n",
       "669337                        [(Herbert G. Dorsey, [a1])]  1908-07-01   \n",
       "669338                          [(S. R. Williams., [a1])]  1908-07-01   \n",
       "669339                           [(Anthony Zeleny, [a1])]  1908-08-01   \n",
       "669340                          [(Frances G. Wick, [a1])]  1908-08-01   \n",
       "669341                                                 []  1908-12-01   \n",
       "\n",
       "                                                 paperAff  \n",
       "0       {'a1': 'CERN, CH-1211 Geneva 23, Switzerland',...  \n",
       "1       {'a1': 'Institute of Modern Physics, CAS, Lanz...  \n",
       "2       {'a1': 'Universität Rostock, Institut für Allg...  \n",
       "3       {'a1': 'Sandia National Laboratories, Albuquer...  \n",
       "4       {'a1': 'National Synchrotron Radiation Researc...  \n",
       "...                                                   ...  \n",
       "669337  {'a1': 'Physical Laboratory, Cornell University'}  \n",
       "669338  {'a1': 'Barnard College, Columbia University, ...  \n",
       "669339  {'a1': 'Physical Laboratory, University of Min...  \n",
       "669340  {'a1': 'Physical Laboratory, Cornell Universit...  \n",
       "669341                                             no aff  \n",
       "\n",
       "[669342 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02609738-642e-4dde-9f2d-7f1b8b82ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669342/669342 [01:16<00:00, 8741.43it/s] \n"
     ]
    }
   ],
   "source": [
    "aid = []\n",
    "author_name = []\n",
    "alter_name = []\n",
    "doi = []\n",
    "ref_set = []\n",
    "coauthor_set = []\n",
    "author_aff = []\n",
    "first_letter = []\n",
    "last_name = []\n",
    "name_split = []\n",
    "gid = []\n",
    "journal = []\n",
    "raw_name = []\n",
    "count = 0\n",
    "test = 0\n",
    "for i in tqdm.tqdm(range(len(meta_data))):\n",
    "    p_doi = meta_data.paperDoi.iloc[i]\n",
    "    authors_info = meta_data.authorName.iloc[i]\n",
    "    #author id\n",
    "    pap_aids = [str(count+i) for i in range(len(authors_info))]\n",
    "    ## affiliation name\n",
    "    paper_aff_dict = meta_data.paperAff.iloc[i]\n",
    "    \n",
    "    for a_info in authors_info:\n",
    "        aname = a_info[0].lower().strip().replace('_','')\n",
    "        if aname[0] in set(['\\n', '\\u2008', '<', '\\xa0', '.', '[', '(']):\n",
    "            test+=1\n",
    "            break\n",
    "        aid.append(set([str(count)]))\n",
    "        gid.append(str(count))\n",
    "        aname_fix = re.sub(u\"\\\\(.*\\\\)|\\\\{.*}|\\\\[.*]\", \"\", aname).replace(', jr.','').replace(' jr.','').strip()\n",
    "        author_name.append(aname_fix) #author list\n",
    "        alter_name.append(set([aname_fix])) #candidate author list\n",
    "        raw_name.append(a_info[0])\n",
    "        sp_list = aname_fix.split()\n",
    "        name_split.append(sp_list)\n",
    "        first_letter.append(aname_fix[0])\n",
    "        last_name.append(sp_list[-1])\n",
    "        \n",
    "        aff_name = []\n",
    "        for i in a_info[1]:\n",
    "            if paper_aff_dict == 'no aff':\n",
    "                aff_name.append('no aff name') \n",
    "            elif i in paper_aff_dict:\n",
    "                aff_name.append(paper_aff_dict[i].lower()) \n",
    "        author_aff.append(set(aff_name)) # multiple affiliation\n",
    "        \n",
    "        doi.append(set([p_doi]))\n",
    "        journal.append(set([re.sub('[\\d,./]', '', p_doi)]))\n",
    "        \n",
    "        ##reference info\n",
    "        if p_doi in reference_dict.keys():\n",
    "            ref_set.append(reference_dict[p_doi])\n",
    "        else:\n",
    "            ref_set.append(set([]))\n",
    "            \n",
    "        ## coauthor\n",
    "        coauthor_set.append(set(pap_aids)-set([str(count)]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "661a1c8a-275f-4193-b114-5be3f60eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper = pd.DataFrame({\n",
    "    'gid':gid,\n",
    "    'aid':aid,\n",
    "    'rawName':raw_name,\n",
    "    'authorName':author_name,\n",
    "    'firstLetter':first_letter,\n",
    "    'lastName':last_name,\n",
    "    'alterName':alter_name,\n",
    "    'nameSplit':name_split,\n",
    "    'doi':doi,\n",
    "    'journal':journal,\n",
    "    'refSet':ref_set,\n",
    "    'coauthorSet':coauthor_set,\n",
    "    'authorAff':author_aff,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85c0ab9d-4c75-4490-bf39-0abfaee78c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254910/254910 [00:09<00:00, 26520.53it/s] \n"
     ]
    }
   ],
   "source": [
    "sim_group = {}\n",
    "for key, value in tqdm.tqdm(author_paper.groupby(['firstLetter','lastName'])):\n",
    "    sim_group[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46b90923-657b-45ca-93d3-ded5433ba1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669342/669342 [00:11<00:00, 60297.24it/s]\n"
     ]
    }
   ],
   "source": [
    "global aff_names\n",
    "aff_names = ''\n",
    "for i in tqdm.tqdm(range(len(meta_data))):\n",
    "    try:\n",
    "        for j in list(meta_data['paperAff'].iloc[i].values()):\n",
    "            term_list = j.replace(',','').replace('.','').lower().split()\n",
    "            term_str = ' '.join(list(set(term_list)))\n",
    "            aff_names+=term_str\n",
    "            aff_names+=' '\n",
    "    except:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ca69bdb-3600-4d37-93e2-44cd175bf0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequency(term, document):\n",
    "    return document.count(term) / float(len(document))\n",
    "\n",
    "def computeTf(document):\n",
    "    sentence = document.replace(',','').replace('.','').lower().split()\n",
    "    tf= dict.fromkeys(set(sentence), 0)\n",
    "    for word in sentence:\n",
    "        tf[word] = termFrequency(word, sentence)\n",
    "    return tf\n",
    "\n",
    "def inverseDocumentFrequency(term, documents): \n",
    "    global idf_dict\n",
    "    if term in idf_dict.keys():\n",
    "        df = idf_dict[term]\n",
    "    else:\n",
    "        df = documents.count(term)\n",
    "        idf_dict[term] = df\n",
    "    return math.log(float(1348385) / df)\n",
    "    \n",
    "def computeIdf(document, documents):\n",
    "    idf_dict = {}\n",
    "    sentence = document.replace(',','').replace('.','').lower().split()\n",
    "    for word in sentence:\n",
    "        idf_dict[word] = inverseDocumentFrequency(word, documents)\n",
    "    return idf_dict\n",
    "\n",
    "def tfIdf(aff_name, aff_names):\n",
    "    vec = {}\n",
    "    vec_tf = computeTf(aff_name)\n",
    "    vec_idf = computeIdf(aff_name, aff_names)\n",
    "    for key in vec_tf.keys():\n",
    "        vec[key] = vec_tf[key]*vec_idf[key]\n",
    "    return vec\n",
    "\n",
    "def calSim(aff_name1, aff_name2, aff_names):\n",
    "    '''\n",
    "    calculate the cosine similarity of two affiliation names\n",
    "    '''\n",
    "    global idf_dict\n",
    "    \n",
    "    tf_idf_1 = tfIdf(aff_name1, aff_names)\n",
    "    tf_idf_2 = tfIdf(aff_name2, aff_names)\n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "\n",
    "    for key in (set(tf_idf_1.keys()).union(set(tf_idf_2.keys()))):\n",
    "        if key in tf_idf_1.keys():\n",
    "            vec1.append(tf_idf_1[key])\n",
    "        else:\n",
    "            vec1.append(0)\n",
    "        if key in tf_idf_2.keys():\n",
    "            vec2.append(tf_idf_2[key])\n",
    "        else:\n",
    "            vec2.append(0)\n",
    "            \n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    sim = vec1.dot(vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "740d45ac-c672-4f30-9290-b685a30d498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSameNameSet(nameset1, nameset2):\n",
    "    '''\n",
    "    Determine whether the two sets of names refer to the same person.\n",
    "    If the two sets have same full name, return 1; else return 2. \n",
    "    If the two sets repel each other, return False.\n",
    "    '''\n",
    "    flag = '2'\n",
    "    for name1 in nameset1:\n",
    "        for name2 in nameset2:\n",
    "            if isSameName(name1, name2):\n",
    "                if ('1' in isSameName(name1, name2)):#same full name\n",
    "                    return '1'\n",
    "    for name1 in nameset1:\n",
    "        for name2 in nameset2:\n",
    "            if not bool(isSameName(name1, name2)):\n",
    "                return False\n",
    "    return flag\n",
    "def isSameName(name1, name2):\n",
    "    global aisian_names\n",
    "    '''\n",
    "    Determine whether two names refer to the same person.\n",
    "    If the two names are all full names and totally same, return 1. \n",
    "    If one of the two names are in abbreviation and both of them compatible with each other, return 2. \n",
    "    If the two names repel each other, return False.\n",
    "    '''\n",
    "    name1_list = re.findall(r'[^\\-\\s]+', name1.replace('.','. '))\n",
    "    name2_list = re.findall(r'[^\\-\\s]+', name2.replace('.','. '))\n",
    "\n",
    "    flag = '1' #same full name\n",
    "    if (len(name1_list) == len(name2_list)):\n",
    "        for i in range(len(name1_list)):\n",
    "            part1 = name1_list[i]\n",
    "            part2 = name2_list[i]\n",
    "            if ('.' not in part1)&('.' not in part2):\n",
    "                if part1!=part2: ## Names without abbreviations need to have the same name\n",
    "                    return False  \n",
    "            else: #Names with abbreviations only need to have the same first letter of the first name\n",
    "                if part1[0]!=part2[0]:\n",
    "                    return False\n",
    "                else:\n",
    "                    flag = '2'\n",
    "\n",
    "    else:\n",
    "        flag = '2' \n",
    "        for i in range(min(len(name1_list), len(name2_list))):\n",
    "            part1 = name1_list[i]\n",
    "            part2 = name2_list[i]\n",
    "            if ('.' not in part1)&('.' not in part2):\n",
    "                if part1!=part2: \n",
    "                    return False  \n",
    "            else:\n",
    "                if part1[0]!=part2[0]:\n",
    "                    return False\n",
    "    return flag\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11c76798-16a5-43d0-9f5d-7248bf8e1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine whether the institutions are similar\n",
    "def ifSameAff():\n",
    "    global aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    " \n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):                                                     \n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if authorAff_list[i] & authorAff_list[j]:\n",
    "                    update_list(i,j)\n",
    "                    stop_set.append(j)   \n",
    "\n",
    "                \n",
    "        del_list(stop_set)\n",
    "        \n",
    "        i+=1 \n",
    "    \n",
    "    return True\n",
    "\n",
    "# Determine whether the journals are similar\n",
    "def ifSameJournal():\n",
    "    global aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    " \n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):                            \n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if bool(journal_list[i] & journal_list[j]):\n",
    "                    update_list(i,j)                                                              \n",
    "                    stop_set.append(j)   \n",
    "\n",
    "        del_list(stop_set)\n",
    "        \n",
    "        i+=1 \n",
    "    \n",
    "    return True\n",
    "\n",
    "# Determine whether the author names are similar\n",
    "def ifSimilar(sim_thres):\n",
    "    global idf_dict, aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    " \n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "    \n",
    "        for j in range(i+1, len(aid_list)):\n",
    "\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                sims = []\n",
    "                for aff_name1 in authorAff_list[i]:\n",
    "                    for aff_name2 in authorAff_list[j]:\n",
    "                        sims.append(calSim(aff_name1, aff_name2, aff_names))\n",
    "                    \n",
    "                if len(sims)!=0:\n",
    "                    if max(sims) >= sim_thres:\n",
    "                        update_list(i,j)\n",
    "                        stop_set.append(j)\n",
    "        \n",
    "        del_list(stop_set)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Determine whether the coauthors are similar\n",
    "def ifCoauthor(): \n",
    "\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    " \n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "        stop_set = []\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "                                    \n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "                    \n",
    "                if coauthorSet_list[i] & coauthorSet_list[j]: \n",
    "\n",
    "                    update_list(i,j)\n",
    "                    stop_set.append(j)\n",
    "        \n",
    "        del_list(stop_set)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    return True\n",
    "\n",
    "# determines whether the authors cite each others publications\n",
    "def ifrefEachOther():\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "        \n",
    "        for j in range(i+1, len(aid_list)):\n",
    "            \n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "                \n",
    "                if (doi_list[j] & refSet_list[i]) & (doi_list[i] & refSet_list[j]):\n",
    "                    update_list(i,j)\n",
    "                    stop_set.append(j)\n",
    "        del_list(stop_set)\n",
    "    \n",
    "        i+=1\n",
    "    return True\n",
    "\n",
    "# determine whether the authors have same whole name (without abbreviations in their names).\n",
    "def ifSameWholeName():\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i<len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "        \n",
    "        for j in range(i+1, len(aid_list)):\n",
    "            \n",
    "            if isSameNameSet(aname_list[i], aname_list[j])=='1':\n",
    "\n",
    "                update_list(i,j)\n",
    "                stop_set.append(j)\n",
    "                    \n",
    "        del_list(stop_set)\n",
    "    \n",
    "        i+=1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f65d72f-5daa-40b4-9508-b22a8d87eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_list(i, j):\n",
    "    '''\n",
    "    after each iteration, update the disambiguation list:\n",
    "    merge the records identified as one author.\n",
    "    '''\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list\n",
    "    aid_list[i]=aid_list[i]|aid_list[j]\n",
    "    aname_list[i]=aname_list[i]|aname_list[j]\n",
    "    doi_list[i]=doi_list[i]|doi_list[j]\n",
    "    refSet_list[i]=refSet_list[i]|refSet_list[j]\n",
    "                \n",
    "    #  update_author\n",
    "    if gid_list[j] in co_update_dict.keys():\n",
    "        co_update_dict[gid_list[j]].update(aid_list[i])\n",
    "    else:\n",
    "        co_update_dict[gid_list[j]] = aid_list[i]\n",
    "    coauthorSet_list[i]=coauthorSet_list[i]|coauthorSet_list[j]\n",
    "    authorAff_list[i]=authorAff_list[i]|authorAff_list[j]\n",
    "    journal_list[i] = journal_list[i]|journal_list[j]\n",
    "    \n",
    "\n",
    "def del_list(stop_set):\n",
    "    '''\n",
    "    after each iteration, update the disambiguation list:\n",
    "    delete the merged records.\n",
    "    '''\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list\n",
    "    aid_list = [aid_list[k] for k in range(0, len(aid_list), 1) if k not in stop_set]\n",
    "    aname_list = [aname_list[k] for k in range(0, len(aname_list), 1) if k not in stop_set]\n",
    "    gid_list = [gid_list[k] for k in range(0, len(gid_list), 1) if k not in stop_set]\n",
    "    doi_list = [doi_list[k] for k in range(0, len(doi_list), 1) if k not in stop_set]\n",
    "    refSet_list = [refSet_list[k] for k in range(0, len(refSet_list), 1) if k not in stop_set]\n",
    "    coauthorSet_list = [coauthorSet_list[k] for k in range(0, len(coauthorSet_list), 1) if k not in stop_set]\n",
    "    authorAff_list = [authorAff_list[k] for k in range(0, len(authorAff_list), 1) if k not in stop_set]  \n",
    "    journal_list = [journal_list[k] for k in range(0, len(journal_list), 1) if k not in stop_set]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "984df034-81e2-4d89-8005-d8af92287c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "global co_update_dict, idf_dict, pair_set_dict\n",
    "idf_dict = {}\n",
    "idf_dict = load_pkl('../data/processing_data/idf_dict.pkl')\n",
    "co_update_dict = {}\n",
    "pair_set_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d7f35c4-26a3-4d6f-96d9-dd6caf92c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aid=[]\n",
    "aname = []\n",
    "gid=[]\n",
    "doi=[]\n",
    "refSet=[]\n",
    "coauthorSet=[]\n",
    "authorAff=[]\n",
    "\n",
    "SIM_THRESHOLD = 0.15\n",
    "count = 0\n",
    "\n",
    "loop_group = {}\n",
    "\n",
    "for key in tqdm.tqdm(sim_group.keys()):\n",
    "           \n",
    "    df = sim_group[key]\n",
    "    \n",
    "    if count%20000 == 0 :\n",
    "        print('key=',key)\n",
    "\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, journal_list\n",
    "    ## dynamic update info\n",
    "    aid_list=list(df.aid)\n",
    "    aname_list=list(df.alterName)\n",
    "    gid_list=list(df.gid)\n",
    "    doi_list = list(df.doi)\n",
    "    refSet_list = list(df.refSet)\n",
    "    coauthorSet_list = list(df.coauthorSet)\n",
    "    journal_list= list(df.journal)\n",
    "\n",
    "    for idx in range(len(coauthorSet_list)):\n",
    "        if coauthorSet_list[idx]&co_update_dict.keys(): \n",
    "            for item in coauthorSet_list[idx]&co_update_dict.keys():\n",
    "                coauthorSet_list[idx].update(co_update_dict[item])\n",
    "\n",
    "    authorAff_list = list(df.authorAff)\n",
    "\n",
    "    if len(df)!=1: \n",
    "\n",
    "        loop = True\n",
    "        while loop:\n",
    "            df_length =len(aid_list)\n",
    "            \n",
    "            ifSameAff() \n",
    "            ifSimilar(0.15)\n",
    "            \n",
    "            ifrefEachOther() \n",
    "            ifCoauthor()\n",
    "            if (len(aid_list)==df_length):\n",
    "                loop = False\n",
    "        \n",
    "        ifSameWholeName()\n",
    "        ifSameJournal()\n",
    "        \n",
    "        loop = True\n",
    "        while loop:\n",
    "            df_length =len(aid_list)\n",
    "            ifrefEachOther() \n",
    "            ifCoauthor()\n",
    "            if (len(aid_list)==df_length):\n",
    "                loop = False\n",
    "                \n",
    "    aid+=aid_list\n",
    "    aname+=aname_list\n",
    "    gid+=gid_list\n",
    "    doi+=doi_list\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "137e9437-f40f-4608-b2c8-09b59b95212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper_2 = pd.DataFrame({\n",
    "    'aid':aid,\n",
    "    'aname':aname,\n",
    "    'gid':gid,\n",
    "    'doi':doi,\n",
    "})\n",
    "author_paper_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815683a-81fa-449e-8da3-c9534d5a5492",
   "metadata": {},
   "source": [
    "### merge authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca652395-b325-4a5c-8c43-686dc4919986",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_data = load_pkl('../data/processing_data/meta_paper_data_3.pkl')\n",
    "author_paper_2 = load_pkl('../data/processing_data/author_paper_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "347a7a15-eaed-4f8c-917a-49ea1f93400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper_3 = author_paper_2\n",
    "author_paper_3.doi = [str(i)[1:-1] for i in author_paper_2['doi']]\n",
    "author_paper_3 = author_paper_3.drop(['doi'], axis=1).join(author_paper_3['doi'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('paperDoi'))\n",
    "author_paper_3['paperDoi'] = [i.strip().strip('\\'') for i in author_paper_3.paperDoi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f1407ab-6453-4716-96dc-4754cdf59c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "APS_author2DOI = author_paper_3[['gid','paperDoi']].rename(columns= {'gid':'aid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ada2861-a238-4642-8667-9b56f263385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper = pd.merge(paper_data[['paperDoi','date','genres','logCit','citCount']], APS_author2DOI, on=['paperDoi']).sort_values(by=['aid','date'],ascending=(True,True)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "481ee061-e5fb-411a-88e5-8bc36eb3034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_group = {}\n",
    "for key, values in all_paper.groupby('aid'):\n",
    "    author_group[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f12da179-0286-49e6-b893-d6338de9a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395678/395678 [03:05<00:00, 2133.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# select publications with PACS codes before 2016\n",
    "author_group_5 = {}\n",
    "for i in tqdm.tqdm(author_group.keys()):\n",
    "    df = author_group[i]\n",
    "    time_df = df[df.date < datetime.date(2016, 1, 1)]\n",
    "    if (sum([bool(g) for g in time_df.genres]) == len(time_df)) & (len(time_df)>0):\n",
    "        author_group_5[i] = time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18458542-5318-446b-b764-d8e48f37520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250040/250040 [01:01<00:00, 4045.13it/s]\n"
     ]
    }
   ],
   "source": [
    "aid = []\n",
    "date = []\n",
    "citCount = []\n",
    "refCount = []\n",
    "paperCount = []\n",
    "genres = []\n",
    "logCit = []\n",
    "paperDoi = []\n",
    "for a in tqdm.tqdm(author_group_5.keys()):\n",
    "    df = author_group_5[a]\n",
    "    aid.extend(df.aid)\n",
    "    date.extend(df.date)\n",
    "    paperDoi.extend(df.paperDoi)\n",
    "    citCount.extend(df.citCount)\n",
    "    paperCount.extend([len(df)]*len(df))\n",
    "    genres.extend([list(set(i)) for i in df.genres])\n",
    "    logCit.extend(df.logCit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac95d2f7-26fc-492a-8e75-677f52001d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper = pd.DataFrame({\n",
    "    'aid':aid,\n",
    "    'date':date,\n",
    "    'paperDoi':paperDoi,\n",
    "    'citCount':citCount,\n",
    "    'paperCount':paperCount,\n",
    "    'genres':genres,\n",
    "    'logCit':logCit,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4dbdea2f-c514-4aad-a3ff-0e87721032b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../data/processing_data/author_paper.pkl',author_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484faaeb-5433-4cb2-ba55-e5341cec4182",
   "metadata": {},
   "source": [
    "# EP & ED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c32c32-3cac-4f19-8573-5153dc038a04",
   "metadata": {},
   "source": [
    "## define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1aa8c2-00a7-411f-90a1-643b5d5e47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level(genres):\n",
    "    listlevel = []\n",
    "    for i in genres:\n",
    "        thislist=[]\n",
    "        for k in i:\n",
    "            thislist.append(k[:2])\n",
    "        thislist=list((thislist))\n",
    "        listlevel.append(thislist)  \n",
    "    return listlevel\n",
    "\n",
    "def matrix_jaccard(matrix,i,j):\n",
    "    '''\n",
    "    Description: calculate the similarity of any two topics\n",
    "    Input: matrix: topic co-occurrence matrix, i:topic i, j:topic j\n",
    "    Output: three similarity indicators of topic i and topic j: Jaccard, Weighted Jaccard, Weighted Overlap\n",
    "    '''\n",
    "    list1 = np.array(list(matrix[i,:]))\n",
    "    list2 = np.array(list(matrix[j,:]))\n",
    "    \n",
    "    overset = ( ( np.array(list1) >0 ) & ( np.array(list2) >0 ))\n",
    "    \n",
    "    sum_overset = np.sum( overset)\n",
    "    \n",
    "    if(sum_overset!=0):  #node i and node j have overlap node\n",
    "        unweight =   sum_overset /  np.sum( ( np.array(list1) >0 ) | ( np.array(list2) >0 ) )\n",
    "\n",
    "        fenzi = np.sum(  np.multiply(  overset.astype('int') , np.array(list1)+np.array(list2)  )    )/2  \n",
    "        fenmu = (  sum( list1 ) + sum( list2 )  )\n",
    "\n",
    "        weight =   fenzi/fenmu\n",
    "        overlap = fenzi/(  fenmu - fenzi - matrix[i,j] -matrix[j,i]   )\n",
    "        \n",
    "        if(overlap<0 or overlap>1 ):\n",
    "            print(i,j)\n",
    "        \n",
    "        return unweight,weight,overlap\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0,0,0\n",
    "\n",
    "def formulate_similarity_distance(matrix):\n",
    "    for k in tq.tqdm(range(0,len(matrix))):\n",
    "        matrix[k][k] =0\n",
    "        for k_2 in range(k+1,len(matrix)):\n",
    "            matrix[k][k_2] =1-matrix[k][k_2]\n",
    "            matrix[k_2][k] =1-matrix[k_2][k]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f041c4-1bab-4a2c-9bb4-9c85353d4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_def(before_genres, now_genres, method):\n",
    "    '''\n",
    "    Description：determine whether the current paper is exploratory paper\n",
    "    Input：before_genres: the area set of papers in look-back period, now_genres: the area set of current paper, method: we only use \"loose\" in our work\n",
    "    Output：whether the current paper is exploratory paper\n",
    "    '''\n",
    "    if method == \"loose\":\n",
    "        for g in now_genres:\n",
    "            if g not in before_genres:\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        for g in now_genres:\n",
    "            if g in before_genres:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "def distance_def(before_genres, now_genres):\n",
    "    '''\n",
    "    Description：calculate the paper distance of the current paper\n",
    "    Input：before_genres: the topic set of papers in look-back period, now_genres: the topic set of current paper\n",
    "    Output：the paper distance of the current paper\n",
    "    '''\n",
    "    result = 0\n",
    "    count = 0\n",
    "    for idx,now_genre in enumerate(now_genres):\n",
    "        if now_genre not in num_genres:\n",
    "            continue\n",
    "        for before_genre in before_genres:\n",
    "            if before_genre not in num_genres:\n",
    "                continue\n",
    "            dis = node_similarity['level1_overlap_matrix'][num_genres[before_genre], num_genres[now_genre]]\n",
    "            result += dis\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return np.nan\n",
    "    return result/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f5918-11d5-4ef5-b918-281702147c3f",
   "metadata": {},
   "source": [
    "## bulid topic co_ocurrence graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22096528-b1ad-4c63-84f0-f68c0f194930",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/processing_data/'\n",
    "author_paper = pd.read_pickle(datapath+\"/author_paper.pkl\")\n",
    "author_paper['genres_level0'] = get_level(list(author_paper.genres))\n",
    "\n",
    "#get index_topic dict\n",
    "num_genres =   list(set(list(chain(*list(author_paper.genres)))))\n",
    "num_genres.sort()\n",
    "num_genres = dict(zip  (  num_genres ,range(0,len(num_genres))  ))\n",
    "\n",
    "num_genres_level0 =   list(set(list(chain(*list(author_paper.genres_level0)))))\n",
    "num_genres_level0.sort()\n",
    "num_genres_level0 = dict(zip  ( num_genres_level0 ,range(0,len(num_genres_level0))   ))\n",
    "\n",
    "len(num_genres),len(num_genres_level0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b186a-c174-4c4d-a7f8-e1d40fde791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get graph link weight\n",
    "matrix = np.zeros( [len(num_genres) ,len(num_genres) ]  )\n",
    "for i in tq.tqdm(author_paper.drop_duplicates(subset=['paperDoi']).genres):\n",
    "    for k in range(0,len(i)):\n",
    "        for k_2 in range(k+1,len(i)):\n",
    "            matrix[num_genres[i[k]],num_genres[i[k_2]]]+=1/(len(i)-1)\n",
    "            matrix[num_genres[i[k_2]],num_genres[i[k]]]+=1/(len(i)-1)\n",
    "for i in range(0,len(matrix)):\n",
    "    matrix[i][i]=0\n",
    "\n",
    "save_pkl(( '../data/processing_data/occurence_matrix.pkl'),matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c41f14-7766-4d63-b255-48583bfb5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get weighted overlap indicator: \n",
    "level1_overlap_matrix = np.zeros( [len(num_genres) ,len(num_genres) ]  )\n",
    "for k in tq.tqdm(range(0,len(matrix))):\n",
    "    for k_2 in range(k+1,len(matrix)):\n",
    "        result = matrix_jaccard(matrix,k,k_2)\n",
    "        level1_overlap_matrix[k,k_2] = result[2]\n",
    "        level1_overlap_matrix[k_2,k] = result[2]\n",
    "        \n",
    "node_similarity ={}\n",
    "node_similarity['level1_overlap_matrix'] = level1_overlap_matrix\n",
    "node_similarity['level1_overlap_matrix'] = formulate_similarity_distance(node_similarity['level1_overlap_matrix'])\n",
    "\n",
    "save_pkl('../data/processing_data/co_code_dis.pkl',[node_similarity['level1_overlap_matrix'],num_genres])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821d755-2aa4-4059-bf05-24856fffad8e",
   "metadata": {},
   "source": [
    "## calculate authors' EP&ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0b9e1-001a-482e-9faa-8f24917263c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper['two_code_genres'] = author_paper['genres'].apply(lambda x:[g[:2] for g in x])\n",
    "author_paper['date'] = author_paper['date'].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc765c9-a7d0-4d4e-b5d2-7427015d4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "aids = []\n",
    "\n",
    "last_year = []\n",
    "this_year = []\n",
    "\n",
    "bert_N1_distance = []\n",
    "bert_N2_distance = []\n",
    "bert_N3_distance = []\n",
    "bert_N4_distance = []\n",
    "bert_N5_distance = []\n",
    "bert_N6_distance = []\n",
    "bert_N7_distance = []\n",
    "bert_N8_distance = []\n",
    "bert_N9_distance = []\n",
    "bert_N10_distance = []\n",
    "bert_N11_distance = []\n",
    "bert_N12_distance = []\n",
    "bert_N13_distance = []\n",
    "bert_N14_distance = []\n",
    "bert_N15_distance = []\n",
    "bert_distance = []\n",
    "\n",
    "N1_ES = []\n",
    "N2_ES = []\n",
    "N3_ES = []\n",
    "N4_ES = []\n",
    "N5_ES = []\n",
    "N6_ES = []\n",
    "N7_ES = []\n",
    "N8_ES = []\n",
    "N9_ES = []\n",
    "N10_ES = []\n",
    "N11_ES = []\n",
    "N12_ES = []\n",
    "N13_ES = []\n",
    "N14_ES = []\n",
    "N15_ES = []\n",
    "Loose_ES = []\n",
    "\n",
    "# look-back period\n",
    "N = 15\n",
    "for aid, personal_info in tqdm(author_paper.groupby(by='aid')):\n",
    "    \n",
    "    before_N_genres = []\n",
    "    before_N_genres_dis = []\n",
    "\n",
    "    before_genres = set()\n",
    "    before_genres_dis = []\n",
    "\n",
    "    first_genre = personal_info['two_code_genres'].iloc[0]\n",
    "    first_genre_dis = personal_info['genres'].iloc[0]\n",
    "\n",
    "    before_N_genres.append(first_genre)\n",
    "    before_N_genres_dis.append(first_genre_dis)\n",
    "\n",
    "    for g in first_genre:\n",
    "        before_genres.add(g)\n",
    "    for g in first_genre_dis:\n",
    "        before_genres_dis.append(g)\n",
    "\n",
    "    for pid in range(1, len(personal_info)):\n",
    "        aids.append(aid)\n",
    "\n",
    "        last_year.append(personal_info['date'].iloc[pid - 1])\n",
    "        this_year.append(personal_info['date'].iloc[pid])\n",
    "\n",
    "        # EP\n",
    "        now_N_genres = []\n",
    "        for i in range(N):\n",
    "            es_name = eval(\"N%d_ES\"%(i+1))\n",
    "\n",
    "            if len(before_N_genres) < i+1:\n",
    "                es_name.append( explore_def(now_N_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\") )\n",
    "            else:\n",
    "                for g in before_N_genres[-(1+i)]:\n",
    "                    now_N_genres.append(g)\n",
    "                es_name.append( explore_def(now_N_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\") )\n",
    "        Loose_ES.append( explore_def(before_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\") )\n",
    "\n",
    "        # ED\n",
    "        now_N_genres = []\n",
    "        for i in range(N):\n",
    "            distance_name = eval(\"bert_N%d_distance\"%(i+1))\n",
    "            if len(before_N_genres_dis) < i+1:\n",
    "                distance_name.append( distance_def(now_N_genres, personal_info[\"genres\"].iloc[pid]) )\n",
    "            else:\n",
    "                for g in before_N_genres_dis[-(1+i)]:\n",
    "                    now_N_genres.append(g)\n",
    "                distance_name.append( distance_def(now_N_genres, personal_info[\"genres\"].iloc[pid]) )\n",
    "        bert_distance.append( distance_def(before_genres_dis, personal_info[\"genres\"].iloc[pid]) )\n",
    "\n",
    "        # update topic and areas list\n",
    "        before_N_genres.append(personal_info[\"two_code_genres\"].iloc[pid])\n",
    "        before_N_genres_dis.append(personal_info[\"genres\"].iloc[pid])\n",
    "\n",
    "        if len(before_N_genres) > N:\n",
    "            before_N_genres.pop(0)\n",
    "        if len(before_N_genres_dis) > N:\n",
    "            before_N_genres_dis.pop(0)\n",
    "\n",
    "        for g in personal_info['two_code_genres'].iloc[pid]:\n",
    "            before_genres.add(g)\n",
    "        for g in personal_info['genres'].iloc[pid]:\n",
    "            before_genres_dis.append(g)\n",
    "            \n",
    "distance_info = pd.DataFrame(\n",
    "    {\n",
    "        \"aid\":aids,\n",
    "        \"lastDate\":last_year,\n",
    "        \"thisDate\":this_year,\n",
    "        \"N1_es_distance\":bert_N1_distance,\n",
    "        \"N2_es_distance\":bert_N2_distance,\n",
    "        \"N3_es_distance\":bert_N3_distance,\n",
    "        \"N4_es_distance\":bert_N4_distance,\n",
    "        \"N5_es_distance\":bert_N5_distance,\n",
    "        \"N6_es_distance\":bert_N6_distance,\n",
    "        \"N7_es_distance\":bert_N7_distance,\n",
    "        \"N8_es_distance\":bert_N8_distance,\n",
    "        \"N9_es_distance\":bert_N9_distance,\n",
    "        \"N10_es_distance\":bert_N10_distance,\n",
    "        \"N11_es_distance\":bert_N11_distance,\n",
    "        \"N12_es_distance\":bert_N12_distance,\n",
    "        \"N13_es_distance\":bert_N13_distance,\n",
    "        \"N14_es_distance\":bert_N14_distance,\n",
    "        \"N15_es_distance\":bert_N15_distance,\n",
    "        \"All_es_distance\":bert_distance,\n",
    "        \"N1_es\":N1_ES,\n",
    "        \"N2_es\":N2_ES,\n",
    "        \"N3_es\":N3_ES,\n",
    "        \"N4_es\":N4_ES,\n",
    "        \"N5_es\":N5_ES,\n",
    "        \"N6_es\":N6_ES,\n",
    "        \"N7_es\":N7_ES,\n",
    "        \"N8_es\":N8_ES,\n",
    "        \"N9_es\":N9_ES,\n",
    "        \"N10_es\":N10_ES,\n",
    "        \"N11_es\":N11_ES,\n",
    "        \"N12_es\":N12_ES,\n",
    "        \"N13_es\":N13_ES,\n",
    "        \"N14_es\":N14_ES,\n",
    "        \"N15_es\":N15_ES,\n",
    "        \"Loose_es\":Loose_ES,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c11565-0719-477d-8ae8-3fa78c278fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_info.to_pickle('../data/processing_data/avg_switch_distance_info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d626d40-4384-48bf-a380-50bf08938ed2",
   "metadata": {},
   "source": [
    "# select scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bffc35e-a23b-4b35-9e45-2b67d07e8c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_paper = pd.read_csv('/public/aps/summarized_data/author_paper.csv')\n",
    "distance_info = pd.read_csv('/public/aps/summarized_data/avg_switch_distance_info.csv')\n",
    "author_paper['date'] = [datetime.datetime.strptime(d,'%Y-%m-%d').date() for d in author_paper['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd53902c-7fe1-4a0f-b619-b3ee13240bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250031/250031 [00:18<00:00, 13749.47it/s]\n"
     ]
    }
   ],
   "source": [
    "first_date_dict = {}\n",
    "paper_count_dict = {}\n",
    "career_year_dict = {}\n",
    "for aid,group in tqdm.tqdm(author_paper.groupby(by='aid')):\n",
    "    first_date_dict[aid] = group['date'].iloc[0]\n",
    "    paper_count_dict[aid] = len(group)\n",
    "    career_year_dict[aid] = (group['date'].iloc[-1]-group['date'].iloc[0]).days//365\n",
    "author_paper[\"CareerYear\"] = author_paper[[\"date\", \"aid\"]].apply(lambda row:row.date - first_date_dict[row.aid], axis=1)\n",
    "author_paper[\"CareerYear\"] = author_paper[\"CareerYear\"].apply(lambda x:x.days//365)+1\n",
    "author_paper[\"paperCount\"] = author_paper.apply(lambda x:paper_count_dict[x.aid], axis=1)\n",
    "author_paper[\"cyCount\"] = author_paper.apply(lambda x:career_year_dict[x.aid], axis=1)\n",
    "\n",
    "distance_info[\"CareerYear\"] = distance_info[[\"thisDate\", \"aid\"]].apply(lambda row:datetime.datetime.strptime(row.thisDate,'%Y-%m-%d').date() - first_date_dict[row.aid], axis=1)\n",
    "distance_info[\"CareerYear\"] = distance_info[\"CareerYear\"].apply(lambda x:x.days//365)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03b8ba69-2d0f-4403-83b9-4879d22f44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for aid,presonal_info in distance_info.groupby(by='aid'):\n",
    "    for i in range(2, len(presonal_info)+2):\n",
    "        numbers.append(i)\n",
    "distance_info['attempt_number'] = numbers     \n",
    "numbers = []\n",
    "for aid,presonal_info in author_paper.groupby(by='aid'):\n",
    "    for i in range(1, len(presonal_info)+1):\n",
    "        numbers.append(i)\n",
    "author_paper['attempt_number'] = numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15849694-5934-4e11-8092-1268f971fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper = author_paper[author_paper.paperCount>=10]\n",
    "author_paper.to_csv('../data/regression/original_aps.csv',index=False)\n",
    "switch.to_csv('../data/regression/switch.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
