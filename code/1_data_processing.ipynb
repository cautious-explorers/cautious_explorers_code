{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c9fcfa-89b9-4df5-ad04-8de1777fd419",
   "metadata": {},
   "source": [
    "In this notebook, we show our data processing steps from the paper information offered by the APS to the main data we use in the following analyses.  \n",
    "The raw data can be requested at https://journals.aps.org/datasets, where the introduction of data can also be acquired. The main data we use in the following analyses include two tables. One includes the scientific impact of each author's each publication and the other includes the exploratory metrics of each author's each publication.   \n",
    "In the [structuralize raw data](#structuralize-raw-data) section, we process the raw json files and create a table of paper information.  \n",
    "In the [count five-year citations](#count-five-year-citations) section, we count the citations each paper received in the five years after its publication, then we take the log-citations as our evaluation metrics of scientific impact.  \n",
    "In the [assign areas and topics](#assign-areas-and-topics) section, we assign the PACS code to each paper.  \n",
    "In the [name disambiguation](#name-disambiguation) section, we perform name disambiguation for authors using their public information. Thus we can have an accurate publication list for each author.  \n",
    "In the [EP & ED](#EP-&-ED) section, we show our calculation process of exploratory propensity (EP) and exploratory distance (ED) based on PACS codes.  \n",
    "In the [Select Scientists](#select-Scientists) section, we select authors who have at least 10 publications as our study objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd95fab-cfd0-447b-8db2-397c3b1c7400",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "In this section, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8b2d118a-8f91-4164-b0af-990d4bc190a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5_1_PSW.R', '6_temporal_perspectives.ipynb', 'draw', '1_data_processing.ipynb', '3_sample_scientist.ipynb', '2_interplays.ipynb', '4_regression_result.ipynb', '.ipynb_checkpoints', '5_2_PSW_result.ipynb', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import scipy.io as scio\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "from itertools import *\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "\n",
    "def save_pkl(path, obj):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b95e12-2f5e-451e-9a0a-13e83d442988",
   "metadata": {},
   "source": [
    "## structuralize raw data\n",
    "The raw data are json files of each publication, in this section, we process the raw json files and create a table of paper information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ceb0a430-9f54-49fa-8970-994baf00d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1031it [11:21,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_doi = []\n",
    "authors_name = []\n",
    "dates = []\n",
    "paper_type = []\n",
    "# the path where you put the raw file from APS\n",
    "for pairs in tqdm.tqdm(os.walk(\"/public/aps/raw_data/aps-dataset-metadata-2020/\", topdown=False)):\n",
    "    root = pairs[0]\n",
    "    files = pairs[2]\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        author_name = []\n",
    "        with open(path, 'r') as f:  # read json files\n",
    "            data = json.load(f)\n",
    "\n",
    "            date_list = list(map(int, data['date'].split('-')))\n",
    "            date = datetime.date(date_list[0], date_list[1], date_list[2])\n",
    "            dates.append(date)\n",
    "\n",
    "            paper_doi.append(data['id'])\n",
    "\n",
    "            if 'articleType' in data.keys():\n",
    "                paper_type.append(data['articleType'])\n",
    "            else:\n",
    "                paper_type.append(None)\n",
    "\n",
    "            if 'authors' in data.keys():\n",
    "                for i in range(len(data['authors'])):\n",
    "                    author_name.append(data['authors'][i]['name'])\n",
    "            else:\n",
    "                author_name = None\n",
    "            authors_name.append(author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b07bbab9-e014-48b0-80c4-77798787a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_paper_data = pd.DataFrame({\n",
    "    'paperDoi': paper_doi,\n",
    "    'authorName': authors_name,\n",
    "    'date': dates,\n",
    "    'type': paper_type\n",
    "})\n",
    "# save_pkl('../data/processing_data/meta_paper_data.pkl', meta_paper_data) # if you want to save the file, uncomment the line:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61b4aaf5-f8c9-48c0-a6c5-3908b49a9b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1893, 7, 1), datetime.date(2020, 12, 31), 678961)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_paper_data.date.min(), meta_paper_data.date.max(), len(meta_paper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef67f99-4617-4bf1-97a6-bec86673bcdd",
   "metadata": {},
   "source": [
    "## count five-year citations\n",
    "APS provides the publications' citation pairs for us. We utilize the pairs to count the logarithm of the number of citations each paper received within five years after it was published (5-year log-citations, $\\log c_5$) and merge it with meta_paper_data we get above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de07071c-9a4b-4bdc-b82c-4e47f12dbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each citation pair, add the publication date for both citing paper and cited paper\n",
    "# meta_paper_data = load_pkl('./meta_paper_data.pkl') # if you want to read the file, uncomment the line:)\n",
    "doi_date = dict(zip(meta_paper_data.paperDoi, meta_paper_data.date))\n",
    "# the path where you put the raw file from APS\n",
    "cit_pair = pd.read_csv('/public/aps/raw_data/aps-dataset-citations-2020.csv')\n",
    "cit_pair_with_time = pd.merge(cit_pair, meta_paper_data[['paperDoi', 'date']].rename(columns={\n",
    "                              'paperDoi': 'citing_doi', 'date': 'citing_pubdate'}), on='citing_doi', how='left').drop_duplicates()\n",
    "cit_pair_with_time = pd.merge(cit_pair_with_time, meta_paper_data[['paperDoi', 'date']].rename(\n",
    "    columns={'paperDoi': 'cited_doi', 'date': 'cited_pubdate'}), on='cited_doi', how='left').drop_duplicates()\n",
    "cit_pair_with_time = cit_pair_with_time.dropna().reset_index(\n",
    "    drop=True)  # delete record without time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f67d38f-fe29-4c1f-918a-096cbbbc88eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8767868/8767868 [05:31<00:00, 26412.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Count the list of references and citations for each paper\n",
    "n = 5  # time windows for citation count\n",
    "citation_dict = {}\n",
    "reference_dict = {}\n",
    "\n",
    "for i in tqdm.tqdm(range(len(cit_pair_with_time))):\n",
    "    # for each citation pair\n",
    "    cited_pub_i = cit_pair_with_time.cited_pubdate.iloc[i] # publication date of cited paper\n",
    "    citing_pub_i = cit_pair_with_time.citing_pubdate.iloc[i] # publication date of citing paper\n",
    "    delta = citing_pub_i-cited_pub_i \n",
    "    cited_doi_i = cit_pair_with_time.cited_doi.iloc[i] # DOI of cited paper\n",
    "    citing_doi_i = cit_pair_with_time.citing_doi.iloc[i] # DOI of citing paper\n",
    "\n",
    "    # for cited list\n",
    "    if (delta >= datetime.timedelta(days=0)) & (delta <= datetime.timedelta(days=n*365)):  # 5years= 365*5 days\n",
    "        if cited_doi_i in citation_dict.keys():\n",
    "            citation_dict[cited_doi_i].add(citing_doi_i)\n",
    "        else:\n",
    "            citation_dict[cited_doi_i] = set([citing_doi_i])\n",
    "\n",
    "    # for reference list\n",
    "    if citing_doi_i in reference_dict.keys():\n",
    "        reference_dict[citing_doi_i].add(cited_doi_i)\n",
    "    else:\n",
    "        reference_dict[citing_doi_i] = set([cited_doi_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be849cb6-4543-4a77-add8-6f5b395fa015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678916/678916 [00:07<00:00, 91951.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# add number of citations to meta_paper_data\n",
    "meta_paper_data = meta_paper_data.drop_duplicates(subset=['paperDoi', 'date'])\n",
    "citations = []\n",
    "references = []\n",
    "cit_count = []\n",
    "ref_count = []\n",
    "for i in tqdm.tqdm(range(len(meta_paper_data))):\n",
    "    paperdoi = meta_paper_data.paperDoi.iloc[i]\n",
    "    if paperdoi in citation_dict.keys():\n",
    "        citations.append(citation_dict[paperdoi])\n",
    "        cit_count.append(len(citation_dict[paperdoi]))\n",
    "    else:\n",
    "        citations.append(set([]))\n",
    "        cit_count.append(0)\n",
    "    if paperdoi in reference_dict.keys():\n",
    "        references.append(reference_dict[paperdoi])\n",
    "        ref_count.append(len(reference_dict[paperdoi]))\n",
    "    else:\n",
    "        references.append(set([]))\n",
    "        ref_count.append(0)\n",
    "\n",
    "meta_paper_data_2 = meta_paper_data.copy()\n",
    "meta_paper_data_2['citations'] = citations\n",
    "meta_paper_data_2['citCount'] = cit_count\n",
    "meta_paper_data_2['references'] = references\n",
    "meta_paper_data_2['refCount'] = ref_count\n",
    "\n",
    "meta_paper_data_2 = meta_paper_data_2.drop_duplicates(\n",
    "    subset=['paperDoi', 'date']).reset_index(drop=True)\n",
    "# visualization of mean log c5 of each year\n",
    "meta_paper_data_2['logCit'] = [np.log(i+1)\n",
    "                               for i in meta_paper_data_2['citCount']]\n",
    "save_pkl('../data/processing_data/meta_paper_data_2.pkl', meta_paper_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f536d7d-bef7-47d5-ba26-254017f86b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d55472910>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_paper_data_2['year'] = [i.year for i in meta_paper_data_2['date']]\n",
    "plt.plot(meta_paper_data_2.groupby('year').logCit.mean()[:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fb0b7-8700-48af-98e8-96b9bbf42537",
   "metadata": {},
   "source": [
    "## assign areas and topics\n",
    "APS provides the PACS codes of each paper for us. We process the '.txt' file and then add the topics information for each paper to our 'meta_paper_data' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bebc1cc4-644d-4d8f-8b04-5ef71ad86318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441340/441340 [00:04<00:00, 107618.48it/s]\n",
      "100%|██████████| 441340/441340 [00:04<00:00, 110199.84it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 111982.59it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 115720.06it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 121311.53it/s]\n",
      "100%|██████████| 441340/441340 [00:04<00:00, 109483.64it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 110418.99it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 113887.28it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 117769.19it/s]\n",
      "100%|██████████| 441340/441340 [00:03<00:00, 122161.58it/s]\n",
      "100%|██████████| 441340/441340 [00:00<00:00, 782248.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "441340"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PACS = pd.read_csv('/public/aps/raw_data/PACS.txt', keep_default_na=False) # the txt file provided by the APS\n",
    "def get_genre(name):\n",
    "    '''\n",
    "    Input: 'PACS1~5' for different PACS codes of all papers, '1' for the first, '5' for the last.\n",
    "    Output: a PACS codes list\n",
    "    '''\n",
    "    PACS_code = []\n",
    "    for i in tqdm.tqdm(range(len(PACS))):\n",
    "        p_code = re.match(r'((.*)([0-9]{4})(.*))', str(\n",
    "            PACS[name].iloc[i]).replace('.', '').replace(' ', '').replace(':', ''))\n",
    "        if p_code:\n",
    "            if p_code.group(1)[:2].isdigit():\n",
    "                PACS_code.append(p_code.group(1)[:6].replace(\n",
    "                    '−', '-').replace('–', '-'))\n",
    "            else:\n",
    "                PACS_code.append(None)\n",
    "        else:\n",
    "            PACS_code.append(None)\n",
    "    return PACS_code\n",
    "\n",
    "# all PACS codes\n",
    "genres_set = set(get_genre('PACS1') + get_genre('PACS2') +\n",
    "                 get_genre('PACS3') + get_genre('PACS4') + get_genre('PACS5'))\n",
    "\n",
    "\n",
    "PACS1 = get_genre('PACS1')\n",
    "PACS2 = get_genre('PACS2')\n",
    "PACS3 = get_genre('PACS3')\n",
    "PACS4 = get_genre('PACS4')\n",
    "PACS5 = get_genre('PACS5')\n",
    "\n",
    "# build a dict of DOI-PACSlist\n",
    "genres_list = []\n",
    "for i in tqdm.tqdm(range(len(PACS))):\n",
    "    gl = [PACS1[i], PACS2[i], PACS3[i], PACS4[i], PACS5[i]]\n",
    "    while None in gl:\n",
    "        gl.remove(None)\n",
    "    genres_list.append(gl)\n",
    "\n",
    "doi_cor_genre = dict(zip(PACS.DOI, genres_list))\n",
    "len(doi_cor_genre)\n",
    "# doi_cor_genre['10.1103/PhysRevA.60.R2614'] = ['0365Bz', '4250Dv', '89701c']\n",
    "# doi_cor_genre['10.1103/PhysRevB.66.104415'] = ['7570Pa', '71301h', '78202e']\n",
    "# doi_cor_genre['10.1103/PhysRevE.65.026128'] = ['05202y', '04402b', '05901m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4adf4af3-5e87-4ae3-b209-eb60dd09b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_paper_data_2 = load_pkl('../data/processing_data/meta_paper_data_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "926d695b-d084-488b-82b4-d08f71f12159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678916/678916 [00:10<00:00, 64393.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# add PACS codes to meta_paper_data\n",
    "genres = []\n",
    "for i in tqdm.tqdm(range(len(meta_paper_data_2))):\n",
    "    if meta_paper_data_2.paperDoi.iloc[i] in doi_cor_genre.keys():\n",
    "        genres.append(doi_cor_genre[meta_paper_data_2.paperDoi.iloc[i]])\n",
    "    else:\n",
    "        genres.append(None)\n",
    "\n",
    "meta_paper_data_3 = meta_paper_data_2.copy()\n",
    "meta_paper_data_3['genres'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e848bb89-afe0-404a-9c96-6a04840ef2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../data/processing_data/meta_paper_data_3.pkl', meta_paper_data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcb5f3-a83d-4c6e-a527-91f0d2e85dfd",
   "metadata": {},
   "source": [
    "## name disambiguation\n",
    "In this section we perform name disambiguation for authors using their public information. \n",
    "1. We process the json files to a dataframe with affiliation information. \n",
    "2. We treat each author from any publication as if each were unique. \n",
    "3. We merge the similar authors through several criteria.\n",
    "4. We build a dataframe of information of each author's each publication, using the merged author data and paper data we get above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034e20b-2acb-4116-9f0d-7193d8ae8300",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c376f2a7-9a04-4998-a45b-51be8ad12a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1031it [11:17,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# structuralize the json file, include affiliation information\n",
    "paper_doi = []\n",
    "authors_name = []\n",
    "dates = []\n",
    "paper_affs = []\n",
    "for pairs in tqdm.tqdm(os.walk(\"/public/aps/raw_data/aps-dataset-metadata-2020/\", topdown=False)):\n",
    "    root = pairs[0]\n",
    "    files = pairs[2]\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        author_name = []\n",
    "        with open(path, 'r') as f:  # read json files\n",
    "            data = json.load(f)\n",
    "\n",
    "            # split features and store them in list\n",
    "            date_list = list(map(int, data['date'].split('-')))\n",
    "            date = datetime.date(date_list[0], date_list[1], date_list[2])\n",
    "            dates.append(date)\n",
    "\n",
    "            paper_doi.append(data['id'])\n",
    "\n",
    "            if 'authors' in data.keys():\n",
    "                for i in range(len(data['authors'])):\n",
    "                    if 'affiliationIds' in data['authors'][i].keys():\n",
    "                        author_name.append(\n",
    "                            (data['authors'][i]['name'], data['authors'][i]['affiliationIds']))\n",
    "                    else:\n",
    "                        author_name = None\n",
    "                        break\n",
    "\n",
    "            else:  # some authors do not have name\n",
    "                author_name = None\n",
    "            authors_name.append(author_name)\n",
    "\n",
    "            if 'affiliations' in data.keys():\n",
    "                aff_dict = {}\n",
    "                for aff in data['affiliations']:\n",
    "                    aff_dict[aff['id']] = aff['name']\n",
    "                paper_affs.append(aff_dict)\n",
    "            else:\n",
    "                paper_affs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3b887bb-1e28-43f9-adef-60d57abfeb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.DataFrame({\n",
    "    'paperDoi': paper_doi,\n",
    "    'authorName': authors_name,\n",
    "    'date': dates,\n",
    "    'paperAff': paper_affs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110ee7-b677-45f3-af3f-0e4cd80f62c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### process procedure\n",
    "We build a table of authors' information, treating each author from any publication as if each were unique. Then we divide the authors into different groups, authors in each group have same last name and initial of first name. Within each group we merge similar authors through the following steps:\n",
    "1. For each iteration, we merge authors who(1) are in similar affiliation,(2) cite each other, or (3) have co-authors.\n",
    "2. After one iteration, we update the data by (1) merging same authors and (2) deleting merged records.\n",
    "3. In the later period of the merging procedure, when there is no update through the first three criteria, we merge authors have publications in the same journal (which means they have similar study field) and have same whole names (which means they are most probably the same person). \n",
    "4. Then we merge authors who cite each other or have co-authors for several iterations, until there is no new update. \n",
    "(Note that for each merge we make sure there is no conflict between author information.)\n",
    "Finally we get a dataframe of each author's publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f85dfab-02dd-4da1-9146-91bca4a0ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62e2bdd9-0c66-46c2-bbc0-055b9245aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 652703/652703 [01:15<00:00, 8634.37it/s] \n"
     ]
    }
   ],
   "source": [
    "# author - paper information\n",
    "aid = []\n",
    "author_name = []\n",
    "alter_name = []\n",
    "doi = []\n",
    "ref_set = []\n",
    "coauthor_set = []\n",
    "author_aff = []\n",
    "first_letter = []\n",
    "last_name = []\n",
    "name_split = []\n",
    "gid = []\n",
    "journal = []\n",
    "raw_name = []\n",
    "count = 0\n",
    "test = 0\n",
    "for i in tqdm.tqdm(range(len(meta_data))):\n",
    "    # for each publication\n",
    "    p_doi = meta_data.paperDoi.iloc[i]\n",
    "    authors_info = meta_data.authorName.iloc[i]\n",
    "    pap_aids = [str(count+i) for i in range(len(authors_info))]\n",
    "    paper_aff_dict = meta_data.paperAff.iloc[i]\n",
    "    \n",
    "    for a_info in authors_info:\n",
    "        # for each author\n",
    "        aname = a_info[0].lower().strip().replace('_','')\n",
    "        if aname[0] in set(['\\n', '\\u2008', '<', '\\xa0', '.', '[', '(']):\n",
    "            test+=1\n",
    "            break\n",
    "        aid.append(set([str(count)]))\n",
    "        gid.append(str(count))\n",
    "        aname_fix = re.sub(u\"\\\\(.*\\\\)|\\\\{.*}|\\\\[.*]\", \"\", aname).replace(', jr.','').replace(' jr.','').strip()\n",
    "        author_name.append(aname_fix)\n",
    "        alter_name.append(set([aname_fix]))\n",
    "        raw_name.append(a_info[0])\n",
    "        sp_list = aname_fix.split()\n",
    "        name_split.append(sp_list)\n",
    "        first_letter.append(aname_fix[0])\n",
    "        last_name.append(sp_list[-1])\n",
    "        \n",
    "        aff_name = []\n",
    "        for i in a_info[1]:\n",
    "            if i in paper_aff_dict:\n",
    "                aff_name.append(paper_aff_dict[i].lower()) \n",
    "        author_aff.append(set(aff_name))\n",
    "        \n",
    "        doi.append(set([p_doi]))\n",
    "        journal.append(set([re.sub('[\\d,./]', '', p_doi)]))\n",
    "        if p_doi in reference_dict.keys():\n",
    "            ref_set.append(reference_dict[p_doi])\n",
    "        else:\n",
    "            ref_set.append(set([]))\n",
    "        coauthor_set.append(set(pap_aids)-set([str(count)]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "661a1c8a-275f-4193-b114-5be3f60eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper = pd.DataFrame({\n",
    "    'gid': gid,\n",
    "    'aid': aid,\n",
    "    'rawName': raw_name,\n",
    "    'authorName': author_name,\n",
    "    'firstLetter': first_letter,\n",
    "    'lastName': last_name,\n",
    "    'alterName': alter_name,\n",
    "    'nameSplit': name_split,\n",
    "    'doi': doi,\n",
    "    'journal': journal,\n",
    "    'refSet': ref_set,\n",
    "    'coauthorSet': coauthor_set,\n",
    "    'authorAff': author_aff,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85c0ab9d-4c75-4490-bf39-0abfaee78c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254531/254531 [00:49<00:00, 5149.37it/s]  \n"
     ]
    }
   ],
   "source": [
    "sim_group = {}\n",
    "for key, value in tqdm.tqdm(author_paper.groupby(['firstLetter', 'lastName'])):\n",
    "    sim_group[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46b90923-657b-45ca-93d3-ded5433ba1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678959/678959 [00:12<00:00, 53869.06it/s]\n"
     ]
    }
   ],
   "source": [
    "meta_data = load_pkl('../data/processing_data/meta_data.pkl')\n",
    "# all affiliation names\n",
    "global aff_names\n",
    "aff_names = ''\n",
    "for i in tqdm.tqdm(range(len(meta_data))):\n",
    "    try:\n",
    "        for j in list(meta_data['paperAff'].iloc[i].values()):\n",
    "            term_list = j.replace(',', '').replace('.', '').lower().split()\n",
    "            term_str = ' '.join(list(set(term_list)))\n",
    "            aff_names += term_str\n",
    "            aff_names += ' '\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ca69bdb-3600-4d37-93e2-44cd175bf0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# several functions for calculating cosine similarity with TF-IDF\n",
    "def termFrequency(term, document):\n",
    "    return document.count(term) / float(len(document))\n",
    "\n",
    "\n",
    "def computeTf(document):\n",
    "    sentence = document.replace(',', '').replace('.', '').lower().split()\n",
    "    tf = dict.fromkeys(set(sentence), 0)\n",
    "    for word in sentence:\n",
    "        tf[word] = termFrequency(word, sentence)\n",
    "    return tf\n",
    "\n",
    "\n",
    "def inverseDocumentFrequency(term, documents):\n",
    "    global idf_dict\n",
    "    if term in idf_dict.keys():\n",
    "        df = idf_dict[term]\n",
    "    else:\n",
    "        df = documents.count(term)\n",
    "        idf_dict[term] = df\n",
    "    return math.log(float(1348385) / df)\n",
    "\n",
    "\n",
    "def computeIdf(document, documents):\n",
    "    idf_dict = {}\n",
    "    sentence = document.replace(',', '').replace('.', '').lower().split()\n",
    "    for word in sentence:\n",
    "        idf_dict[word] = inverseDocumentFrequency(word, documents)\n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "def tfIdf(aff_name, aff_names):\n",
    "    vec = {}\n",
    "    vec_tf = computeTf(aff_name)\n",
    "    vec_idf = computeIdf(aff_name, aff_names)\n",
    "    for key in vec_tf.keys():\n",
    "        vec[key] = vec_tf[key]*vec_idf[key]\n",
    "    return vec\n",
    "\n",
    "\n",
    "def calSim(aff_name1, aff_name2, aff_names):\n",
    "    '''\n",
    "    calculate the cosine similarity of two affiliation names\n",
    "    '''\n",
    "    global idf_dict\n",
    "\n",
    "    tf_idf_1 = tfIdf(aff_name1, aff_names)\n",
    "    tf_idf_2 = tfIdf(aff_name2, aff_names)\n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "\n",
    "    for key in (set(tf_idf_1.keys()).union(set(tf_idf_2.keys()))):\n",
    "        if key in tf_idf_1.keys():\n",
    "            vec1.append(tf_idf_1[key])\n",
    "        else:\n",
    "            vec1.append(0)\n",
    "        if key in tf_idf_2.keys():\n",
    "            vec2.append(tf_idf_2[key])\n",
    "        else:\n",
    "            vec2.append(0)\n",
    "\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    sim = vec1.dot(vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "740d45ac-c672-4f30-9290-b685a30d498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSameNameSet(nameset1, nameset2):\n",
    "    '''\n",
    "    Determine whether the two sets of names refer to the same person.\n",
    "    If the two sets have same full name, return 1; else return 2. \n",
    "    If the two sets repel each other, return False.\n",
    "    '''\n",
    "    flag = '2'\n",
    "    for name1 in nameset1:\n",
    "        for name2 in nameset2:\n",
    "            if isSameName(name1, name2):\n",
    "                if ('1' in isSameName(name1, name2)):  # same full name\n",
    "                    return '1'\n",
    "    for name1 in nameset1:\n",
    "        for name2 in nameset2:\n",
    "            if not bool(isSameName(name1, name2)):\n",
    "                return False\n",
    "    return flag\n",
    "\n",
    "\n",
    "def isSameName(name1, name2):\n",
    "    global aisian_names\n",
    "    '''\n",
    "    Determine whether two names refer to the same person.\n",
    "    If the two names are all full names and totally the same, return 1. \n",
    "    If one of the two names are in abbreviation and both of them compatible with each other, return 2. \n",
    "    If the two names repel each other, return False.\n",
    "    '''\n",
    "    name1_list = re.findall(r'[^\\-\\s]+', name1.replace('.', '. '))\n",
    "    name2_list = re.findall(r'[^\\-\\s]+', name2.replace('.', '. '))\n",
    "\n",
    "    flag = '1'  # same full name\n",
    "    if (len(name1_list) == len(name2_list)):\n",
    "        for i in range(len(name1_list)):\n",
    "            part1 = name1_list[i]\n",
    "            part2 = name2_list[i]\n",
    "            if ('.' not in part1) & ('.' not in part2):\n",
    "                if part1 != part2:  # Names without abbreviations need to have the same name\n",
    "                    return False\n",
    "            else:  # Names with abbreviations only need to have the same first letter of the first name\n",
    "                if part1[0] != part2[0]:\n",
    "                    return False\n",
    "                else:\n",
    "                    flag = '2'\n",
    "    else:\n",
    "        flag = '2'\n",
    "        for i in range(min(len(name1_list), len(name2_list))):\n",
    "            part1 = name1_list[i]\n",
    "            part2 = name2_list[i]\n",
    "            if ('.' not in part1) & ('.' not in part2):\n",
    "                if part1 != part2:\n",
    "                    return False\n",
    "            else:\n",
    "                if part1[0] != part2[0]:\n",
    "                    return False\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11c76798-16a5-43d0-9f5d-7248bf8e1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine whether athors have same institution\n",
    "def ifSameAff():\n",
    "    global aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if authorAff_list[i] & authorAff_list[j]:\n",
    "                    update_list(i, j)\n",
    "                    stop_set.append(j)\n",
    "\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return True\n",
    "\n",
    "# Determine whether the authors' publication journals are similar\n",
    "\n",
    "\n",
    "def ifSameJournal():\n",
    "    global aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if bool(journal_list[i] & journal_list[j]):\n",
    "                    update_list(i, j)\n",
    "                    stop_set.append(j)\n",
    "\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return True\n",
    "\n",
    "# Determine whether the authors' names are similar\n",
    "\n",
    "\n",
    "def ifSimilar(sim_thres):\n",
    "    global idf_dict, aff_names, aname_list, aid_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                sims = []\n",
    "                for aff_name1 in authorAff_list[i]:\n",
    "                    for aff_name2 in authorAff_list[j]:\n",
    "                        sims.append(calSim(aff_name1, aff_name2, aff_names))\n",
    "\n",
    "                if len(sims) != 0:\n",
    "                    if max(sims) >= sim_thres:\n",
    "                        update_list(i, j)\n",
    "                        stop_set.append(j)\n",
    "\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return True\n",
    "\n",
    "# Determine whether the coauthors are similar\n",
    "\n",
    "\n",
    "def ifCoauthor():\n",
    "\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "        stop_set = []\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if coauthorSet_list[i] & coauthorSet_list[j]:\n",
    "\n",
    "                    update_list(i, j)\n",
    "                    stop_set.append(j)\n",
    "\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return True\n",
    "\n",
    "# determines whether the authors cite each others publications\n",
    "\n",
    "\n",
    "def ifrefEachOther():\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]):\n",
    "\n",
    "                if (doi_list[j] & refSet_list[i]) & (doi_list[i] & refSet_list[j]):\n",
    "                    update_list(i, j)\n",
    "                    stop_set.append(j)\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "    return True\n",
    "\n",
    "# determine whether the authors have same whole name (without abbreviations in their names).\n",
    "\n",
    "\n",
    "def ifSameWholeName():\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list, pair_set_dict\n",
    "\n",
    "    i = 0\n",
    "    while i < len(aid_list):\n",
    "\n",
    "        stop_set = []\n",
    "\n",
    "        for j in range(i+1, len(aid_list)):\n",
    "\n",
    "            if isSameNameSet(aname_list[i], aname_list[j]) == '1':\n",
    "\n",
    "                update_list(i, j)\n",
    "                stop_set.append(j)\n",
    "\n",
    "        del_list(stop_set)\n",
    "\n",
    "        i += 1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f65d72f-5daa-40b4-9508-b22a8d87eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_list(i, j):\n",
    "    '''\n",
    "    after each iteration, update the disambiguation list:\n",
    "    merge the records identified as one author.\n",
    "    '''\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list\n",
    "    aid_list[i] = aid_list[i] | aid_list[j]\n",
    "    aname_list[i] = aname_list[i] | aname_list[j]\n",
    "    doi_list[i] = doi_list[i] | doi_list[j]\n",
    "    refSet_list[i] = refSet_list[i] | refSet_list[j]\n",
    "\n",
    "    #  update_author\n",
    "    if gid_list[j] in co_update_dict.keys():\n",
    "        co_update_dict[gid_list[j]].update(aid_list[i])\n",
    "    else:\n",
    "        co_update_dict[gid_list[j]] = aid_list[i]\n",
    "    coauthorSet_list[i] = coauthorSet_list[i] | coauthorSet_list[j]\n",
    "    authorAff_list[i] = authorAff_list[i] | authorAff_list[j]\n",
    "    journal_list[i] = journal_list[i] | journal_list[j]\n",
    "\n",
    "\n",
    "def del_list(stop_set):\n",
    "    '''\n",
    "    after each iteration, update the disambiguation list:\n",
    "    delete the merged records.\n",
    "    '''\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, co_update_dict, journal_list\n",
    "    aid_list = [aid_list[k]\n",
    "                for k in range(0, len(aid_list), 1) if k not in stop_set]\n",
    "    aname_list = [aname_list[k]\n",
    "                  for k in range(0, len(aname_list), 1) if k not in stop_set]\n",
    "    gid_list = [gid_list[k]\n",
    "                for k in range(0, len(gid_list), 1) if k not in stop_set]\n",
    "    doi_list = [doi_list[k]\n",
    "                for k in range(0, len(doi_list), 1) if k not in stop_set]\n",
    "    refSet_list = [refSet_list[k]\n",
    "                   for k in range(0, len(refSet_list), 1) if k not in stop_set]\n",
    "    coauthorSet_list = [coauthorSet_list[k] for k in range(\n",
    "        0, len(coauthorSet_list), 1) if k not in stop_set]\n",
    "    authorAff_list = [authorAff_list[k] for k in range(\n",
    "        0, len(authorAff_list), 1) if k not in stop_set]\n",
    "    journal_list = [journal_list[k]\n",
    "                    for k in range(0, len(journal_list), 1) if k not in stop_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "984df034-81e2-4d89-8005-d8af92287c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "global co_update_dict, idf_dict, pair_set_dict\n",
    "idf_dict = {}\n",
    "# idf_dict = load_pkl('../data/processing_data/idf_dict.pkl')\n",
    "co_update_dict = {}\n",
    "pair_set_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f35c4-26a3-4d6f-96d9-dd6caf92c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/254531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key= ('0', 'acher')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/254531 [00:39<100:29:20,  1.42s/it]/root/miniconda3/envs/mytensor/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  8%|▊         | 20001/254531 [1:11:35<19:34:38,  3.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key= ('a', 'schulze-bonhage')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40001/254531 [3:15:20<6:59:03,  8.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key= ('c', 'maurice')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 60002/254531 [6:48:46<94:41:12,  1.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key= ('e', 'choubabi')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 61140/254531 [7:02:36<11:58:25,  4.49it/s] "
     ]
    }
   ],
   "source": [
    "aid = []\n",
    "aname = []\n",
    "gid = []\n",
    "doi = []\n",
    "refSet = []\n",
    "coauthorSet = []\n",
    "authorAff = []\n",
    "\n",
    "SIM_THRESHOLD = 0.15\n",
    "count = 0\n",
    "\n",
    "loop_group = {}\n",
    "\n",
    "for key in tqdm.tqdm(sim_group.keys()):\n",
    "\n",
    "    df = sim_group[key]\n",
    "\n",
    "    if count % 20000 == 0:\n",
    "        print('key=', key)\n",
    "\n",
    "    global aid_list, aname_list, gid_list, doi_list, refSet_list, coauthorSet_list, authorAff_list, journal_list\n",
    "    # dynamic update info\n",
    "    aid_list = list(df.aid)\n",
    "    aname_list = list(df.alterName)\n",
    "    gid_list = list(df.gid)\n",
    "    doi_list = list(df.doi)\n",
    "    refSet_list = list(df.refSet)\n",
    "    coauthorSet_list = list(df.coauthorSet)\n",
    "    journal_list = list(df.journal)\n",
    "\n",
    "    for idx in range(len(coauthorSet_list)):\n",
    "        if coauthorSet_list[idx] & co_update_dict.keys():\n",
    "            for item in coauthorSet_list[idx] & co_update_dict.keys():\n",
    "                coauthorSet_list[idx].update(co_update_dict[item])\n",
    "\n",
    "    authorAff_list = list(df.authorAff)\n",
    "\n",
    "    if len(df) != 1:\n",
    "\n",
    "        loop = True\n",
    "        while loop:\n",
    "            df_length = len(aid_list)\n",
    "\n",
    "            ifSameAff()\n",
    "            ifSimilar(0.15)\n",
    "\n",
    "            ifrefEachOther()\n",
    "            ifCoauthor()\n",
    "            if (len(aid_list) == df_length):\n",
    "                loop = False\n",
    "\n",
    "        ifSameWholeName()\n",
    "        ifSameJournal()\n",
    "\n",
    "        loop = True\n",
    "        while loop:\n",
    "            df_length = len(aid_list)\n",
    "            ifrefEachOther()\n",
    "            ifCoauthor()\n",
    "            if (len(aid_list) == df_length):\n",
    "                loop = False\n",
    "\n",
    "    aid += aid_list\n",
    "    aname += aname_list\n",
    "    gid += gid_list\n",
    "    doi += doi_list\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "137e9437-f40f-4608-b2c8-09b59b95212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>aname</th>\n",
       "      <th>gid</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{1741261}</td>\n",
       "      <td>{0. acher}</td>\n",
       "      <td>1741261</td>\n",
       "      <td>{10.1103/PhysRevLett.85.2817}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{1741259}</td>\n",
       "      <td>{0. vacus}</td>\n",
       "      <td>1741259</td>\n",
       "      <td>{10.1103/PhysRevLett.85.2817}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{106555, 107021}</td>\n",
       "      <td>{arif -uz -zaman}</td>\n",
       "      <td>106555</td>\n",
       "      <td>{10.1103/PhysRevD.11.2632, 10.1103/PhysRevD.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{521604}</td>\n",
       "      <td>{alfonso pérez a.}</td>\n",
       "      <td>521604</td>\n",
       "      <td>{10.1103/PhysRevE.69.036121}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{1527481, 2063010, 438021}</td>\n",
       "      <td>{alvo aabloo, a. aabloo}</td>\n",
       "      <td>438021</td>\n",
       "      <td>{10.1103/PhysRevSTAB.17.103501, 10.1103/PhysRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276174</th>\n",
       "      <td>{1955331, 1672097, 1953455, 799111, 1269309, 1...</td>\n",
       "      <td>{p. k. mang}</td>\n",
       "      <td>799111</td>\n",
       "      <td>{10.1103/PhysRevLett.93.027002, 10.1103/PhysRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276175</th>\n",
       "      <td>{1413370, 1284086, 1014900, 842883, 1380886, 8...</td>\n",
       "      <td>{p. s. mangat}</td>\n",
       "      <td>842883</td>\n",
       "      <td>{10.1103/PhysRevB.44.6284, 10.1103/PhysRevB.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276176</th>\n",
       "      <td>{1319901}</td>\n",
       "      <td>{p. mangat}</td>\n",
       "      <td>1319901</td>\n",
       "      <td>{10.1103/PhysRevB.46.13471}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276177</th>\n",
       "      <td>{1528581, 1155428}</td>\n",
       "      <td>{p. mangelis, panagiotis mangelis}</td>\n",
       "      <td>1155428</td>\n",
       "      <td>{10.1103/PhysRevB.94.165131, 10.1103/PhysRevB....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276178</th>\n",
       "      <td>{1651114}</td>\n",
       "      <td>{p. mangiagalli}</td>\n",
       "      <td>1651114</td>\n",
       "      <td>{10.1103/PhysRevLett.118.238001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276179 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      aid  \\\n",
       "0                                               {1741261}   \n",
       "1                                               {1741259}   \n",
       "2                                        {106555, 107021}   \n",
       "3                                                {521604}   \n",
       "4                              {1527481, 2063010, 438021}   \n",
       "...                                                   ...   \n",
       "276174  {1955331, 1672097, 1953455, 799111, 1269309, 1...   \n",
       "276175  {1413370, 1284086, 1014900, 842883, 1380886, 8...   \n",
       "276176                                          {1319901}   \n",
       "276177                                 {1528581, 1155428}   \n",
       "276178                                          {1651114}   \n",
       "\n",
       "                                     aname      gid  \\\n",
       "0                               {0. acher}  1741261   \n",
       "1                               {0. vacus}  1741259   \n",
       "2                        {arif -uz -zaman}   106555   \n",
       "3                       {alfonso pérez a.}   521604   \n",
       "4                 {alvo aabloo, a. aabloo}   438021   \n",
       "...                                    ...      ...   \n",
       "276174                        {p. k. mang}   799111   \n",
       "276175                      {p. s. mangat}   842883   \n",
       "276176                         {p. mangat}  1319901   \n",
       "276177  {p. mangelis, panagiotis mangelis}  1155428   \n",
       "276178                    {p. mangiagalli}  1651114   \n",
       "\n",
       "                                                      doi  \n",
       "0                           {10.1103/PhysRevLett.85.2817}  \n",
       "1                           {10.1103/PhysRevLett.85.2817}  \n",
       "2       {10.1103/PhysRevD.11.2632, 10.1103/PhysRevD.11...  \n",
       "3                            {10.1103/PhysRevE.69.036121}  \n",
       "4       {10.1103/PhysRevSTAB.17.103501, 10.1103/PhysRe...  \n",
       "...                                                   ...  \n",
       "276174  {10.1103/PhysRevLett.93.027002, 10.1103/PhysRe...  \n",
       "276175  {10.1103/PhysRevB.44.6284, 10.1103/PhysRevB.41...  \n",
       "276176                        {10.1103/PhysRevB.46.13471}  \n",
       "276177  {10.1103/PhysRevB.94.165131, 10.1103/PhysRevB....  \n",
       "276178                   {10.1103/PhysRevLett.118.238001}  \n",
       "\n",
       "[276179 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_paper_2 = pd.DataFrame({\n",
    "    'aid': aid,\n",
    "    'aname': aname,\n",
    "    'gid': gid,\n",
    "    'doi': doi,\n",
    "})\n",
    "author_paper_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815683a-81fa-449e-8da3-c9534d5a5492",
   "metadata": {},
   "source": [
    "### merge authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ca652395-b325-4a5c-8c43-686dc4919986",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_data = load_pkl('../data/processing_data/meta_paper_data_3.pkl')\n",
    "author_paper_2 = load_pkl('../data/processing_data/author_paper_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "347a7a15-eaed-4f8c-917a-49ea1f93400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper_3 = author_paper_2\n",
    "author_paper_3.doi = [str(i)[1:-1] for i in author_paper_2['doi']]\n",
    "author_paper_3 = author_paper_3.drop(['doi'], axis=1).join(author_paper_3['doi'].str.split(\n",
    "    ',', expand=True).stack().reset_index(level=1, drop=True).rename('paperDoi'))\n",
    "author_paper_3['paperDoi'] = [i.strip().strip('\\'')\n",
    "                              for i in author_paper_3.paperDoi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f1407ab-6453-4716-96dc-4754cdf59c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "APS_author2DOI = author_paper_3[['gid', 'paperDoi']].rename(columns={\n",
    "                                                            'gid': 'aid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada2861-a238-4642-8667-9b56f263385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper = pd.merge(paper_data[['paperDoi', 'date', 'genres', 'logCit', 'citCount']], APS_author2DOI, on=[\n",
    "                     'paperDoi']).sort_values(by=['aid', 'date'], ascending=(True, True)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae4335-8aa1-479e-b6cd-8a3c4eed6696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logCit</th>\n",
       "      <th>citCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2333759.00</td>\n",
       "      <td>2333759.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.47</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.01</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.39</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.20</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.61</td>\n",
       "      <td>2018.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          logCit   citCount\n",
       "count 2333759.00 2333759.00\n",
       "mean        1.47       6.60\n",
       "std         1.01      12.80\n",
       "min         0.00       0.00\n",
       "25%         0.69       1.00\n",
       "50%         1.39       3.00\n",
       "75%         2.20       8.00\n",
       "max         7.61    2018.00"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ee061-e5fb-411a-88e5-8bc36eb3034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_group = {}\n",
    "for key, values in all_paper.groupby('aid'):\n",
    "    author_group[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f12da179-0286-49e6-b893-d6338de9a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395678/395678 [02:59<00:00, 2198.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# select publications with PACS codes before 2016\n",
    "author_group_5 = {}\n",
    "for i in tqdm.tqdm(author_group.keys()):\n",
    "    df = author_group[i]\n",
    "    time_df = df[df.date < datetime.date(2016, 1, 1)]\n",
    "    if (sum([bool(g) for g in time_df.genres]) == len(time_df)) & (len(time_df) > 0):\n",
    "        author_group_5[i] = time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18458542-5318-446b-b764-d8e48f37520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250031/250031 [01:28<00:00, 2816.37it/s]\n"
     ]
    }
   ],
   "source": [
    "aid = []\n",
    "date = []\n",
    "citCount = []\n",
    "refCount = []\n",
    "paperCount = []\n",
    "genres = []\n",
    "logCit = []\n",
    "paperDoi = []\n",
    "for a in tqdm.tqdm(author_group_5.keys()):\n",
    "    df = author_group_5[a]\n",
    "    aid.extend(df.aid)\n",
    "    date.extend(df.date)\n",
    "    paperDoi.extend(df.paperDoi)\n",
    "    citCount.extend(df.citCount)\n",
    "    paperCount.extend([len(df)]*len(df))\n",
    "    genres.extend([list(set(i)) for i in df.genres])\n",
    "    logCit.extend(df.logCit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ac95d2f7-26fc-492a-8e75-677f52001d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper = pd.DataFrame({\n",
    "    'aid': aid,\n",
    "    'date': date,\n",
    "    'paperDoi': paperDoi,\n",
    "    'citCount': citCount,\n",
    "    'paperCount': paperCount,\n",
    "    'genres': genres,\n",
    "    'logCit': logCit,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4dbdea2f-c514-4aad-a3ff-0e87721032b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../data/processing_data/author_paper.pkl', author_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484faaeb-5433-4cb2-ba55-e5341cec4182",
   "metadata": {},
   "source": [
    "# EP & ED\n",
    "First, we define the functions that are used to calculate the scientists' EP&ED.\n",
    "\n",
    "Then, before calculating the ED, we construct a topic co-occurrence graph to calculate the distance between the topics.\n",
    "\n",
    "Finally, we use the scientists' publication data to calculate exploratory metrics for each scientist's career."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c32c32-3cac-4f19-8573-5153dc038a04",
   "metadata": {},
   "source": [
    "## define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8b1aa8c2-00a7-411f-90a1-643b5d5e47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level(genres):\n",
    "    '''\n",
    "    Description: get areas based on topics.\n",
    "    '''\n",
    "    listlevel = []\n",
    "    for i in genres:\n",
    "        thislist = []\n",
    "        for k in i:\n",
    "            thislist.append(k[:2])\n",
    "        thislist = list((thislist))\n",
    "        listlevel.append(thislist)\n",
    "    return listlevel\n",
    "\n",
    "\n",
    "def matrix_jaccard(matrix, i, j):\n",
    "    '''\n",
    "    Description: calculate the similarity of any two topics\n",
    "    Input: matrix: topic co-occurrence matrix, i:topic i, j:topic j\n",
    "    Output: three similarity indicators of topic i and topic j: Jaccard, Weighted Jaccard, Weighted Overlap\n",
    "    '''\n",
    "    list1 = np.array(list(matrix[i, :]))\n",
    "    list2 = np.array(list(matrix[j, :]))\n",
    "\n",
    "    overset = ((np.array(list1) > 0) & (np.array(list2) > 0))\n",
    "\n",
    "    sum_overset = np.sum(overset)\n",
    "\n",
    "    if (sum_overset != 0):  # node i and node j have overlap node\n",
    "        unweight = sum_overset / \\\n",
    "            np.sum((np.array(list1) > 0) | (np.array(list2) > 0))\n",
    "\n",
    "        fenzi = np.sum(np.multiply(overset.astype('int'),\n",
    "                       np.array(list1)+np.array(list2)))/2\n",
    "        fenmu = (sum(list1) + sum(list2))\n",
    "\n",
    "        weight = fenzi/fenmu\n",
    "        overlap = fenzi/(fenmu - fenzi - matrix[i, j] - matrix[j, i])\n",
    "\n",
    "        if (overlap < 0 or overlap > 1):\n",
    "            print(i, j)\n",
    "\n",
    "        return unweight, weight, overlap\n",
    "\n",
    "    else:\n",
    "\n",
    "        return 0, 0, 0\n",
    "\n",
    "\n",
    "def formulate_similarity_distance(matrix):\n",
    "    '''\n",
    "    Description: get topic_distance = 1- topic_similarity\n",
    "    '''\n",
    "    for k in tqdm.tqdm(range(0, len(matrix))):\n",
    "        matrix[k][k] = 0\n",
    "        for k_2 in range(k+1, len(matrix)):\n",
    "            matrix[k][k_2] = 1-matrix[k][k_2]\n",
    "            matrix[k_2][k] = 1-matrix[k_2][k]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e9f041c4-1bab-4a2c-9bb4-9c85353d4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_def(before_genres, now_genres, method):\n",
    "    '''\n",
    "    Description：determine whether the current paper is exploratory paper\n",
    "    Input：before_genres: the area set of papers in look-back period, now_genres: the area set of current paper, method: we only use \"loose\" in our work\n",
    "    Output：whether the current paper is exploratory paper\n",
    "    '''\n",
    "    if method == \"loose\":\n",
    "        for g in now_genres:\n",
    "            if g not in before_genres:\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        for g in now_genres:\n",
    "            if g in before_genres:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "def distance_def(before_genres, now_genres):\n",
    "    '''\n",
    "    Description：calculate the paper distance of the current paper\n",
    "    Input：before_genres: the topic set of papers in look-back period, now_genres: the topic set of current paper\n",
    "    Output：the paper distance of the current paper\n",
    "    '''\n",
    "    result = 0\n",
    "    count = 0\n",
    "    for idx, now_genre in enumerate(now_genres):\n",
    "        if now_genre not in num_genres:\n",
    "            continue\n",
    "        for before_genre in before_genres:\n",
    "            if before_genre not in num_genres:\n",
    "                continue\n",
    "            dis = node_similarity['level1_overlap_matrix'][num_genres[before_genre],\n",
    "                                                           num_genres[now_genre]]\n",
    "            result += dis\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return np.nan\n",
    "    return result/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f5918-11d5-4ef5-b918-281702147c3f",
   "metadata": {},
   "source": [
    "## bulid topic co_ocurrence graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "22096528-b1ad-4c63-84f0-f68c0f194930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5676, 73)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "datapath = '../data/processing_data/'\n",
    "author_paper = pd.read_pickle(datapath+\"/author_paper.pkl\")\n",
    "author_paper['genres_level0'] = get_level(list(author_paper.genres))\n",
    "\n",
    "# mapping of topics and areas\n",
    "num_genres = list(set(list(chain(*list(author_paper.genres)))))\n",
    "num_genres.sort()\n",
    "num_genres = dict(zip(num_genres, range(0, len(num_genres))))\n",
    "\n",
    "num_genres_level0 = list(set(list(chain(*list(author_paper.genres_level0)))))\n",
    "num_genres_level0.sort()\n",
    "num_genres_level0 = dict(\n",
    "    zip(num_genres_level0, range(0, len(num_genres_level0))))\n",
    "\n",
    "len(num_genres), len(num_genres_level0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "460b186a-c174-4c4d-a7f8-e1d40fde791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377897/377897 [00:02<00:00, 183945.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# get graph link weight\n",
    "matrix = np.zeros([len(num_genres), len(num_genres)])\n",
    "for i in tqdm.tqdm(author_paper.drop_duplicates(subset=['paperDoi']).genres):\n",
    "    for k in range(0, len(i)):\n",
    "        for k_2 in range(k+1, len(i)):\n",
    "            matrix[num_genres[i[k]], num_genres[i[k_2]]] += 1/(len(i)-1)\n",
    "            matrix[num_genres[i[k_2]], num_genres[i[k]]] += 1/(len(i)-1)\n",
    "for i in range(0, len(matrix)):\n",
    "    matrix[i][i] = 0\n",
    "\n",
    "save_pkl(('../data/processing_data/occurence_matrix.pkl'), matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abd50e-14e0-481d-b2d0-131eb930ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1192/5676 [1:42:08<6:19:43,  5.08s/it]"
     ]
    }
   ],
   "source": [
    "# get weighted overlap indicator:\n",
    "level1_overlap_matrix = np.zeros([len(num_genres), len(num_genres)])\n",
    "for k in tqdm.tqdm(range(0, len(matrix))):\n",
    "    for k_2 in range(k+1, len(matrix)):\n",
    "        result = matrix_jaccard(matrix, k, k_2)\n",
    "        level1_overlap_matrix[k, k_2] = result[2]\n",
    "        level1_overlap_matrix[k_2, k] = result[2]\n",
    "\n",
    "node_similarity = {}\n",
    "node_similarity['level1_overlap_matrix'] = level1_overlap_matrix\n",
    "node_similarity['level1_overlap_matrix'] = formulate_similarity_distance(\n",
    "    node_similarity['level1_overlap_matrix'])\n",
    "\n",
    "save_pkl('../data/processing_data/co_code_dis.pkl',\n",
    "         [node_similarity['level1_overlap_matrix'], num_genres])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821d755-2aa4-4059-bf05-24856fffad8e",
   "metadata": {},
   "source": [
    "## calculate authors' EP&ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "72cac6ae-e1ae-4cf3-a5fe-8d1bd2b6e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_similarity = {}\n",
    "node_similarity['level1_overlap_matrix'], num_genres = load_pkl('../data/processing_data/co_code_dis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80d0b9e1-001a-482e-9faa-8f24917263c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper['two_code_genres'] = author_paper['genres'].apply(lambda x: [\n",
    "                                                               g[:2] for g in x])\n",
    "author_paper['date'] = author_paper['date'].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a653bcc-96d0-45fe-80aa-301538a35094",
   "metadata": {},
   "outputs": [],
   "source": [
    "aids = []\n",
    "\n",
    "last_year = []\n",
    "this_year = []\n",
    "\n",
    "bert_N1_distance = []\n",
    "bert_N2_distance = []\n",
    "bert_N3_distance = []\n",
    "bert_N4_distance = []\n",
    "bert_N5_distance = []\n",
    "bert_N6_distance = []\n",
    "bert_N7_distance = []\n",
    "bert_N8_distance = []\n",
    "bert_N9_distance = []\n",
    "bert_N10_distance = []\n",
    "bert_N11_distance = []\n",
    "bert_N12_distance = []\n",
    "bert_N13_distance = []\n",
    "bert_N14_distance = []\n",
    "bert_N15_distance = []\n",
    "bert_distance = []\n",
    "\n",
    "N1_ES = []\n",
    "N2_ES = []\n",
    "N3_ES = []\n",
    "N4_ES = []\n",
    "N5_ES = []\n",
    "N6_ES = []\n",
    "N7_ES = []\n",
    "N8_ES = []\n",
    "N9_ES = []\n",
    "N10_ES = []\n",
    "N11_ES = []\n",
    "N12_ES = []\n",
    "N13_ES = []\n",
    "N14_ES = []\n",
    "N15_ES = []\n",
    "Loose_ES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eaeafcb2-1524-4bee-afa1-7615be5a3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25237/25237 [06:44<00:00, 62.41it/s] \n"
     ]
    }
   ],
   "source": [
    "# Calculate the EP and ED for each scientist throughout their career.\n",
    "# Specifically, for each paper, we compare the paper to the paper during the look-back period. \n",
    "# See S2 in Supplementary Information for details of the process.\n",
    "N = 15\n",
    "for aid, personal_info in tqdm.tqdm(author_paper.groupby(by='aid')):\n",
    "\n",
    "    before_N_genres = []\n",
    "    before_N_genres_dis = []\n",
    "\n",
    "    before_genres = set()\n",
    "    before_genres_dis = []\n",
    "\n",
    "    first_genre = personal_info['two_code_genres'].iloc[0]\n",
    "    first_genre_dis = personal_info['genres'].iloc[0]\n",
    "\n",
    "    before_N_genres.append(first_genre)\n",
    "    before_N_genres_dis.append(first_genre_dis)\n",
    "\n",
    "    for g in first_genre:\n",
    "        before_genres.add(g)\n",
    "    for g in first_genre_dis:\n",
    "        before_genres_dis.append(g)\n",
    "\n",
    "    for pid in range(1, len(personal_info)):\n",
    "        aids.append(aid)\n",
    "\n",
    "        last_year.append(personal_info['date'].iloc[pid - 1])\n",
    "        this_year.append(personal_info['date'].iloc[pid])\n",
    "\n",
    "        # EP\n",
    "        now_N_genres = []\n",
    "        for i in range(N):\n",
    "            es_name = eval(\"N%d_ES\" % (i+1))\n",
    "\n",
    "            if len(before_N_genres) < i+1:\n",
    "                es_name.append(explore_def(\n",
    "                    now_N_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\"))\n",
    "            else:\n",
    "                for g in before_N_genres[-(1+i)]:\n",
    "                    now_N_genres.append(g)\n",
    "                es_name.append(explore_def(\n",
    "                    now_N_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\"))\n",
    "        Loose_ES.append(explore_def(\n",
    "            before_genres, personal_info[\"two_code_genres\"].iloc[pid], method=\"loose\"))\n",
    "\n",
    "        # ED\n",
    "        now_N_genres = []\n",
    "        for i in range(N):\n",
    "            distance_name = eval(\"bert_N%d_distance\" % (i+1))\n",
    "            if len(before_N_genres_dis) < i+1:\n",
    "                distance_name.append(distance_def(\n",
    "                    now_N_genres, personal_info[\"genres\"].iloc[pid]))\n",
    "            else:\n",
    "                for g in before_N_genres_dis[-(1+i)]:\n",
    "                    now_N_genres.append(g)\n",
    "                distance_name.append(distance_def(\n",
    "                    now_N_genres, personal_info[\"genres\"].iloc[pid]))\n",
    "        bert_distance.append(distance_def(\n",
    "            before_genres_dis, personal_info[\"genres\"].iloc[pid]))\n",
    "\n",
    "        # update topic and areas list\n",
    "        before_N_genres.append(personal_info[\"two_code_genres\"].iloc[pid])\n",
    "        before_N_genres_dis.append(personal_info[\"genres\"].iloc[pid])\n",
    "\n",
    "        if len(before_N_genres) > N:\n",
    "            before_N_genres.pop(0)\n",
    "        if len(before_N_genres_dis) > N:\n",
    "            before_N_genres_dis.pop(0)\n",
    "\n",
    "        for g in personal_info['two_code_genres'].iloc[pid]:\n",
    "            before_genres.add(g)\n",
    "        for g in personal_info['genres'].iloc[pid]:\n",
    "            before_genres_dis.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bac6b6d3-ee9b-43d3-9982-42684f3470e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organise and save data\n",
    "distance_info = pd.DataFrame(\n",
    "    {\n",
    "        \"aid\": aids,\n",
    "        \"lastDate\": last_year,\n",
    "        \"thisDate\": this_year,\n",
    "        \"N1_es_distance\": bert_N1_distance,\n",
    "        \"N2_es_distance\": bert_N2_distance,\n",
    "        \"N3_es_distance\": bert_N3_distance,\n",
    "        \"N4_es_distance\": bert_N4_distance,\n",
    "        \"N5_es_distance\": bert_N5_distance,\n",
    "        \"N6_es_distance\": bert_N6_distance,\n",
    "        \"N7_es_distance\": bert_N7_distance,\n",
    "        \"N8_es_distance\": bert_N8_distance,\n",
    "        \"N9_es_distance\": bert_N9_distance,\n",
    "        \"N10_es_distance\": bert_N10_distance,\n",
    "        \"N11_es_distance\": bert_N11_distance,\n",
    "        \"N12_es_distance\": bert_N12_distance,\n",
    "        \"N13_es_distance\": bert_N13_distance,\n",
    "        \"N14_es_distance\": bert_N14_distance,\n",
    "        \"N15_es_distance\": bert_N15_distance,\n",
    "        \"All_es_distance\": bert_distance,\n",
    "        \"N1_es\": N1_ES,\n",
    "        \"N2_es\": N2_ES,\n",
    "        \"N3_es\": N3_ES,\n",
    "        \"N4_es\": N4_ES,\n",
    "        \"N5_es\": N5_ES,\n",
    "        \"N6_es\": N6_ES,\n",
    "        \"N7_es\": N7_ES,\n",
    "        \"N8_es\": N8_ES,\n",
    "        \"N9_es\": N9_ES,\n",
    "        \"N10_es\": N10_ES,\n",
    "        \"N11_es\": N11_ES,\n",
    "        \"N12_es\": N12_ES,\n",
    "        \"N13_es\": N13_ES,\n",
    "        \"N14_es\": N14_ES,\n",
    "        \"N15_es\": N15_ES,\n",
    "        \"Loose_es\": Loose_ES,\n",
    "    }\n",
    ")\n",
    "distance_info.to_pickle('../data/processing_data/avg_switch_distance_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c3ae6d3-7e7f-4e05-8054-9841a9b09f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1_es_distance</th>\n",
       "      <th>N2_es_distance</th>\n",
       "      <th>N3_es_distance</th>\n",
       "      <th>N4_es_distance</th>\n",
       "      <th>N5_es_distance</th>\n",
       "      <th>N6_es_distance</th>\n",
       "      <th>N7_es_distance</th>\n",
       "      <th>N8_es_distance</th>\n",
       "      <th>N9_es_distance</th>\n",
       "      <th>N10_es_distance</th>\n",
       "      <th>N11_es_distance</th>\n",
       "      <th>N12_es_distance</th>\n",
       "      <th>N13_es_distance</th>\n",
       "      <th>N14_es_distance</th>\n",
       "      <th>N15_es_distance</th>\n",
       "      <th>All_es_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "      <td>533941.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       N1_es_distance  N2_es_distance  N3_es_distance  N4_es_distance  \\\n",
       "count       533941.00       533941.00       533941.00       533941.00   \n",
       "mean             0.53            0.54            0.54            0.55   \n",
       "std              0.22            0.20            0.20            0.19   \n",
       "min              0.00            0.00            0.00            0.00   \n",
       "25%              0.37            0.40            0.41            0.41   \n",
       "50%              0.53            0.54            0.55            0.55   \n",
       "75%              0.70            0.69            0.68            0.68   \n",
       "max              1.00            1.00            1.00            1.00   \n",
       "\n",
       "       N5_es_distance  N6_es_distance  N7_es_distance  N8_es_distance  \\\n",
       "count       533941.00       533941.00       533941.00       533941.00   \n",
       "mean             0.55            0.55            0.55            0.55   \n",
       "std              0.19            0.19            0.19            0.19   \n",
       "min              0.00            0.00            0.00            0.00   \n",
       "25%              0.42            0.42            0.42            0.42   \n",
       "50%              0.55            0.56            0.56            0.56   \n",
       "75%              0.69            0.69            0.69            0.69   \n",
       "max              1.00            1.00            1.00            1.00   \n",
       "\n",
       "       N9_es_distance  N10_es_distance  N11_es_distance  N12_es_distance  \\\n",
       "count       533941.00        533941.00        533941.00        533941.00   \n",
       "mean             0.56             0.56             0.56             0.56   \n",
       "std              0.19             0.19             0.19             0.19   \n",
       "min              0.00             0.00             0.00             0.00   \n",
       "25%              0.43             0.43             0.43             0.43   \n",
       "50%              0.56             0.56             0.56             0.56   \n",
       "75%              0.69             0.69             0.69             0.69   \n",
       "max              1.00             1.00             1.00             1.00   \n",
       "\n",
       "       N13_es_distance  N14_es_distance  N15_es_distance  All_es_distance  \n",
       "count        533941.00        533941.00        533941.00        533941.00  \n",
       "mean              0.56             0.56             0.56             0.57  \n",
       "std               0.19             0.19             0.19             0.19  \n",
       "min               0.00             0.00             0.00             0.00  \n",
       "25%               0.43             0.43             0.43             0.44  \n",
       "50%               0.56             0.57             0.57             0.57  \n",
       "75%               0.69             0.70             0.70             0.70  \n",
       "max               1.00             1.00             1.00             1.00  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_info.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d626d40-4384-48bf-a380-50bf08938ed2",
   "metadata": {},
   "source": [
    "# Select Scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8bffc35e-a23b-4b35-9e45-2b67d07e8c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_paper = pd.read_pickle('../data/processing_data/author_paper.pkl')\n",
    "distance_info = pd.read_pickle(\n",
    "    '../data/processing_data/avg_switch_distance_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1a4cbb73-63fd-4c28-ae1e-ed0814e21920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>date</th>\n",
       "      <th>paperDoi</th>\n",
       "      <th>citCount</th>\n",
       "      <th>paperCount</th>\n",
       "      <th>genres</th>\n",
       "      <th>logCit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>10.1103/PhysRevA.87.022315</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0367Lx, 0365Yz, 0230Yy]</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>10.1103/PhysRevA.90.062108</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[3380-b, 0365Xp]</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2015-11-09</td>\n",
       "      <td>10.1103/PhysRevA.92.053411</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0365Aa, 0365Xp, 0530Rt, 3280Qk]</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>2004-09-13</td>\n",
       "      <td>10.1103/PhysRevB.70.121201</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[6172Ji, 7155Eq, 7670Hb, 6172Bb]</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>2005-03-18</td>\n",
       "      <td>10.1103/PhysRevB.71.125209</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[6172Ji, 7670Hb, 7155Eq]</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077413</th>\n",
       "      <td>9998</td>\n",
       "      <td>2013-08-19</td>\n",
       "      <td>10.1103/PhysRevB.88.075424</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[7145Gm, 6146Df, 4270-a, 4120Cv]</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077414</th>\n",
       "      <td>9998</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>10.1103/PhysRevB.90.165424</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[7322-f, 7867Bf, 7115Qe]</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077415</th>\n",
       "      <td>999853</td>\n",
       "      <td>1996-12-01</td>\n",
       "      <td>10.1103/PhysRevC.54.3051</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2570Gh, 2570Jj]</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077416</th>\n",
       "      <td>999853</td>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>10.1103/PhysRevC.88.014604</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2540Sc, 8756bd, 2410-i]</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077417</th>\n",
       "      <td>999943</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>10.1103/PhysRevC.87.025805</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[2450+g, 2555Hp, 2560Pj, 2110Pc]</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1077418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aid        date                    paperDoi  citCount  paperCount  \\\n",
       "0           100  2013-02-13  10.1103/PhysRevA.87.022315         4           3   \n",
       "1           100  2014-12-03  10.1103/PhysRevA.90.062108         2           3   \n",
       "2           100  2015-11-09  10.1103/PhysRevA.92.053411         3           3   \n",
       "3          1000  2004-09-13  10.1103/PhysRevB.70.121201         2           2   \n",
       "4          1000  2005-03-18  10.1103/PhysRevB.71.125209         1           2   \n",
       "...         ...         ...                         ...       ...         ...   \n",
       "1077413    9998  2013-08-19  10.1103/PhysRevB.88.075424         2           3   \n",
       "1077414    9998  2014-10-17  10.1103/PhysRevB.90.165424         1           3   \n",
       "1077415  999853  1996-12-01    10.1103/PhysRevC.54.3051         0           2   \n",
       "1077416  999853  2013-07-11  10.1103/PhysRevC.88.014604         0           2   \n",
       "1077417  999943  2013-02-26  10.1103/PhysRevC.87.025805         4           1   \n",
       "\n",
       "                                   genres  logCit  \n",
       "0                [0367Lx, 0365Yz, 0230Yy]    1.61  \n",
       "1                        [3380-b, 0365Xp]    1.10  \n",
       "2        [0365Aa, 0365Xp, 0530Rt, 3280Qk]    1.39  \n",
       "3        [6172Ji, 7155Eq, 7670Hb, 6172Bb]    1.10  \n",
       "4                [6172Ji, 7670Hb, 7155Eq]    0.69  \n",
       "...                                   ...     ...  \n",
       "1077413  [7145Gm, 6146Df, 4270-a, 4120Cv]    1.10  \n",
       "1077414          [7322-f, 7867Bf, 7115Qe]    0.69  \n",
       "1077415                  [2570Gh, 2570Jj]    0.00  \n",
       "1077416          [2540Sc, 8756bd, 2410-i]    0.00  \n",
       "1077417  [2450+g, 2555Hp, 2560Pj, 2110Pc]    1.61  \n",
       "\n",
       "[1077418 rows x 7 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4595253d-4edb-4dd9-b4f6-1db812a5108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250031/250031 [00:20<00:00, 12212.74it/s]\n"
     ]
    }
   ],
   "source": [
    "first_date_dict = {}\n",
    "paper_count_dict = {}\n",
    "career_year_dict = {}\n",
    "for aid, group in tqdm.tqdm(author_paper.groupby(by='aid')):\n",
    "    first_date_dict[aid] = group['date'].iloc[0]\n",
    "    paper_count_dict[aid] = len(group)\n",
    "    career_year_dict[aid] = (group['date'].iloc[-1] -\n",
    "                             group['date'].iloc[0]).days//365+1\n",
    "    \n",
    "author_paper[\"CareerYear\"] = author_paper[[\"date\", \"aid\"]].apply(\n",
    "    lambda row: row.date - first_date_dict[row.aid], axis=1)\n",
    "author_paper[\"CareerYear\"] = author_paper[\"CareerYear\"].apply(\n",
    "    lambda x: x.days//365)+1\n",
    "author_paper[\"paperCount\"] = author_paper.apply(\n",
    "    lambda x: paper_count_dict[x.aid], axis=1)\n",
    "author_paper[\"cyCount\"] = author_paper.apply(\n",
    "    lambda x: career_year_dict[x.aid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "263b1f1a-931c-4707-a660-6b2db0a609cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_info[\"CareerYear\"] = distance_info[[\"thisDate\", \"aid\"]].apply(\n",
    "    lambda row: datetime.datetime.strptime(row.thisDate, '%Y-%m-%d').date() - first_date_dict[row.aid], axis=1)\n",
    "distance_info[\"CareerYear\"] = distance_info[\"CareerYear\"].apply(\n",
    "    lambda x: x.days//365)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "03b8ba69-2d0f-4403-83b9-4879d22f44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for aid, presonal_info in distance_info.groupby(by='aid'):\n",
    "    for i in range(2, len(presonal_info)+2):\n",
    "        numbers.append(i)\n",
    "distance_info['attempt_number'] = numbers\n",
    "numbers = []\n",
    "for aid, presonal_info in author_paper.groupby(by='aid'):\n",
    "    for i in range(1, len(presonal_info)+1):\n",
    "        numbers.append(i)\n",
    "author_paper['attempt_number'] = numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "eaa3fb72-cc5b-4a6c-9fea-eb3fd654a8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25237"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_paper = author_paper[author_paper.paperCount >= 10]\n",
    "author_paper.aid.nunique()#shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "13e29232-bb17-4468-808d-83607dca8354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citCount</th>\n",
       "      <th>paperCount</th>\n",
       "      <th>logCit</th>\n",
       "      <th>CareerYear</th>\n",
       "      <th>cyCount</th>\n",
       "      <th>attempt_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>559178.00</td>\n",
       "      <td>559178.00</td>\n",
       "      <td>559178.00</td>\n",
       "      <td>559178.00</td>\n",
       "      <td>559178.00</td>\n",
       "      <td>559178.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.60</td>\n",
       "      <td>34.94</td>\n",
       "      <td>1.74</td>\n",
       "      <td>10.30</td>\n",
       "      <td>18.36</td>\n",
       "      <td>17.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.60</td>\n",
       "      <td>30.04</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.61</td>\n",
       "      <td>20.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>9.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>15.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.00</td>\n",
       "      <td>321.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>36.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>321.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       citCount  paperCount    logCit  CareerYear   cyCount  attempt_number\n",
       "count 559178.00   559178.00 559178.00   559178.00 559178.00       559178.00\n",
       "mean       8.60       34.94      1.74       10.30     18.36           17.97\n",
       "std       15.60       30.04      0.99        6.81      6.61           20.06\n",
       "min        0.00       10.00      0.00        1.00      1.00            1.00\n",
       "25%        2.00       16.00      1.10        5.00     13.00            6.00\n",
       "50%        5.00       25.00      1.79        9.00     18.00           12.00\n",
       "75%       10.00       43.00      2.40       15.00     23.00           22.00\n",
       "max     2018.00      321.00      7.61       36.00     36.00          321.00"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_paper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f5a1fb87-6373-4c74-99d9-360def26c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper.to_csv('../data/regression/original_aps.csv', index=False)\n",
    "distance_info.to_csv('../data/regression/switch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd196d-13a5-4cf2-8ac9-995e6a170385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c4518-fdf7-4688-aff0-3ad69b2c51e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytensor-kernel",
   "language": "python",
   "name": "mytensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
